{"title":"Buffer of Thoughts (BoT)","markdown":{"yaml":{"title":"Buffer of Thoughts (BoT)","description":"This blog delves into the implementation of an agentic framework leveraging LangGraph’s Long-term memory feature. It demonstrates how this capability enhances the BoT agent’s ability to reason and solve complex problems by retaining and utilizing contextual information over time. Practical examples showcase the potential of LangGraph for building advanced, memory-augmented LLM agents.","author":"Oliver Pfante","date":"2025-01-26","categories":["agentic","code"],"image":"bot_agent.webp","toc":true,"jupyter":"python3","execute":{"enabled":false},"bibliography":"../references.bibtex"},"headingText":"**Key Features of BoT**","containsRefs":false,"markdown":"\n\n\n\n\nThe \"Buffer of Thoughts\" (BoT)[@yang2024bufferthoughtsthoughtaugmentedreasoning] is a framework designed to enhance the **accuracy**, **efficiency**, and **robustness** of Large Language Models (LLMs) in reasoning tasks.\n\n1. **Long-term memory** \n    BoT introduces a **Meta-Buffer**, which serves as a kind of Long-term memory, persisting across different sessions. This repository stores high-level **thought-templates** distilled from prior problem-solving processes. These templates are retrieved and adapted for diverse tasks, eliminating the need to design reasoning structures anew.\n2. **Three Components**\n    - **Problem-Distiller**: Responsible for extracting key information and constraints from tasks.\n    - **Meta-Buffer**: A lightweight memory storing thought-templates, which can span across various categories and domains. While six categories are mentioned in the paper (e.g., text comprehension, mathematical reasoning), the framework is not inherently restricted to this classification or number.\n    - **Buffer-Manager**: Dynamically updates the meta-buffer by distilling new templates as tasks are solved, ensuring the memory evolves with experience.\n3. **Advantages**\n    - **Improved Accuracy**: By adapting templates to different tasks, BoT achieves precise and reliable reasoning.\n    - **Efficiency**: Stored templates allow LLMs to bypass complex multi-query reasoning, streamlining the process.\n    - **Robustness**: The generalized reasoning framework ensures consistent performance across a variety of tasks.\n\n## Notebook Objective\n- Demonstrates the implementation of BoT using **LangGraph**, highlighting Long-term memory capabilities via a `BaseStore` object for persistent storage and retrieval of thought-templates.  \n- Showcases LangGraph's support for dynamic and adaptive memory, enhancing LLMs' reasoning capabilities within the BoT framework.  \n\n![Illustration of the BoT Method. Figure taken from [@yang2024bufferthoughtsthoughtaugmentedreasoning]](bot_agent.png)\n\n## Setup\n\n## Prompts\n\nWe start by writing down the relevant prompts for each of the three components. They are copy-pasted from the original publication.\n\nThe Instantiate Reasoning step is part of the Meta-Buffer and adapts thought-templates to solve specific tasks. It either instantiates a retrieved template with task-specific reasoning structures or assigns a general template for new tasks, ensuring efficient and accurate problem-solving.\n\nThe following prompts outline the behavior of the Buffer-Manager and the process for creating a new template when no suitable template is found during the Meta-Buffer’s template retrieval step. This process, known as *Template Distillation*, involves two key steps: first, summarizing the task using the distilled task description and the derived solution; second, leveraging this summary to perform a contextual search for in-task and cross-task examples, which are then used as few-shot examples to generate the new template.\n\nSome prompts, provided to the [Trustcall Executors](https://github.com/hinthornw/trustcall) defined in the next section, are used to extract structured output from the plain text responses of the LLM.\n\n## Templates\n\nA Pydantic class is used to digest and extract Thought Templates in the required format. It consists of three sections: a \"Task Description\" which provides a brief overview of the task; a \"Solution Description\" which outlines a high-level approach to solving the task; and finally, the \"Thought-Template\" itself, which offers a step-by-step guide for solving the problem.\n\n## Runnables\n\nThe [Lang-Chain Runnables](https://python.langchain.com/docs/concepts/runnables/) encapsulating the main logic of the subsequently defined nodes of the graph.\n\n## Long-term memory\n\nAll Thought-Templates are stored in a Long-term memory to ensure their availability across sessions. The Long-term memory supports semantic search on the Task Description of each Thought-Template, which plays a crucial role in two steps: first, during template retrieval in the Meta-Buffer, where a relevant template is identified for the problem; and second, during Template Distillation by the Buffer-Manager, where it is used to retrieve relevant in-task and cross-task few-shot examples for generating a new template.\n\nOptionally, one can populate the Thought-Template storage with predefined templates like the six ones listed in the appendix of [@yang2024bufferthoughtsthoughtaugmentedreasoning] or one can also start with a blank template store. In any case we need to assign a namespace for the Long-term memory, a kind of table name.\n\n## States\n\nThe state of the LangGraph agent is defined by inheriting from `MessageState`, the default state of LangGraph that stores the message history. Additionally, two more attributes are added, whose values are manipulated during the BoT agent's actions.\n\n## Nodes\n\nNodes of the LangGraph agent which update the state. Each Node maps onto each step of the BoT agent.\n\n## Conditional Edges\n\nIn case a proper Thought-Template was found during the Thought-Template Retrieval step, we skip the distillation of a new template.\n\n## Build the Graph\n\nThe graph representing the BoT agent consists of two sub-graphs: the Meta-Buffer and the Buffer-Manager. The Meta-Buffer handles the Template Retrieval and Reasoning Instantiation steps, while the Buffer-Manager generates a new Thought-Template and updates the Long-term memory if the Template Retrieval step fails to find a matching template for the problem.\n\n## Run the Agent\n\nWe run the agent twice for two different instances of the [Game of 24](https://github.com/princeton-nlp/tree-of-thought-llm)[@yao2023treethoughtsdeliberateproblem] where one needs to create a formula from a list of integers such that the result is 24.\n\nFor the Game of 24 problem, the agent retrieves the Coding Thought-Template and uses it to derive a Python program as a generic solution (caveat: the solution is printed in Polish notation).\n\nThe BoT-Agent generates a new Thought-Template for the 24-Game problem and updates the Long-term memory (aka Meta-Buffer).\n\nWe run the agent a second time for another example of the 24-game.\n\nThis time the agent re-used the previously generated thought template and did not distill a new one for deriving the solution.\n","srcMarkdownNoYaml":"\n\n\n\n\nThe \"Buffer of Thoughts\" (BoT)[@yang2024bufferthoughtsthoughtaugmentedreasoning] is a framework designed to enhance the **accuracy**, **efficiency**, and **robustness** of Large Language Models (LLMs) in reasoning tasks.\n\n## **Key Features of BoT**\n1. **Long-term memory** \n    BoT introduces a **Meta-Buffer**, which serves as a kind of Long-term memory, persisting across different sessions. This repository stores high-level **thought-templates** distilled from prior problem-solving processes. These templates are retrieved and adapted for diverse tasks, eliminating the need to design reasoning structures anew.\n2. **Three Components**\n    - **Problem-Distiller**: Responsible for extracting key information and constraints from tasks.\n    - **Meta-Buffer**: A lightweight memory storing thought-templates, which can span across various categories and domains. While six categories are mentioned in the paper (e.g., text comprehension, mathematical reasoning), the framework is not inherently restricted to this classification or number.\n    - **Buffer-Manager**: Dynamically updates the meta-buffer by distilling new templates as tasks are solved, ensuring the memory evolves with experience.\n3. **Advantages**\n    - **Improved Accuracy**: By adapting templates to different tasks, BoT achieves precise and reliable reasoning.\n    - **Efficiency**: Stored templates allow LLMs to bypass complex multi-query reasoning, streamlining the process.\n    - **Robustness**: The generalized reasoning framework ensures consistent performance across a variety of tasks.\n\n## Notebook Objective\n- Demonstrates the implementation of BoT using **LangGraph**, highlighting Long-term memory capabilities via a `BaseStore` object for persistent storage and retrieval of thought-templates.  \n- Showcases LangGraph's support for dynamic and adaptive memory, enhancing LLMs' reasoning capabilities within the BoT framework.  \n\n![Illustration of the BoT Method. Figure taken from [@yang2024bufferthoughtsthoughtaugmentedreasoning]](bot_agent.png)\n\n## Setup\n\n## Prompts\n\nWe start by writing down the relevant prompts for each of the three components. They are copy-pasted from the original publication.\n\nThe Instantiate Reasoning step is part of the Meta-Buffer and adapts thought-templates to solve specific tasks. It either instantiates a retrieved template with task-specific reasoning structures or assigns a general template for new tasks, ensuring efficient and accurate problem-solving.\n\nThe following prompts outline the behavior of the Buffer-Manager and the process for creating a new template when no suitable template is found during the Meta-Buffer’s template retrieval step. This process, known as *Template Distillation*, involves two key steps: first, summarizing the task using the distilled task description and the derived solution; second, leveraging this summary to perform a contextual search for in-task and cross-task examples, which are then used as few-shot examples to generate the new template.\n\nSome prompts, provided to the [Trustcall Executors](https://github.com/hinthornw/trustcall) defined in the next section, are used to extract structured output from the plain text responses of the LLM.\n\n## Templates\n\nA Pydantic class is used to digest and extract Thought Templates in the required format. It consists of three sections: a \"Task Description\" which provides a brief overview of the task; a \"Solution Description\" which outlines a high-level approach to solving the task; and finally, the \"Thought-Template\" itself, which offers a step-by-step guide for solving the problem.\n\n## Runnables\n\nThe [Lang-Chain Runnables](https://python.langchain.com/docs/concepts/runnables/) encapsulating the main logic of the subsequently defined nodes of the graph.\n\n## Long-term memory\n\nAll Thought-Templates are stored in a Long-term memory to ensure their availability across sessions. The Long-term memory supports semantic search on the Task Description of each Thought-Template, which plays a crucial role in two steps: first, during template retrieval in the Meta-Buffer, where a relevant template is identified for the problem; and second, during Template Distillation by the Buffer-Manager, where it is used to retrieve relevant in-task and cross-task few-shot examples for generating a new template.\n\nOptionally, one can populate the Thought-Template storage with predefined templates like the six ones listed in the appendix of [@yang2024bufferthoughtsthoughtaugmentedreasoning] or one can also start with a blank template store. In any case we need to assign a namespace for the Long-term memory, a kind of table name.\n\n## States\n\nThe state of the LangGraph agent is defined by inheriting from `MessageState`, the default state of LangGraph that stores the message history. Additionally, two more attributes are added, whose values are manipulated during the BoT agent's actions.\n\n## Nodes\n\nNodes of the LangGraph agent which update the state. Each Node maps onto each step of the BoT agent.\n\n## Conditional Edges\n\nIn case a proper Thought-Template was found during the Thought-Template Retrieval step, we skip the distillation of a new template.\n\n## Build the Graph\n\nThe graph representing the BoT agent consists of two sub-graphs: the Meta-Buffer and the Buffer-Manager. The Meta-Buffer handles the Template Retrieval and Reasoning Instantiation steps, while the Buffer-Manager generates a new Thought-Template and updates the Long-term memory if the Template Retrieval step fails to find a matching template for the problem.\n\n## Run the Agent\n\nWe run the agent twice for two different instances of the [Game of 24](https://github.com/princeton-nlp/tree-of-thought-llm)[@yao2023treethoughtsdeliberateproblem] where one needs to create a formula from a list of integers such that the result is 24.\n\nFor the Game of 24 problem, the agent retrieves the Coding Thought-Template and uses it to derive a Python program as a generic solution (caveat: the solution is printed in Polish notation).\n\nThe BoT-Agent generates a new Thought-Template for the 24-Game problem and updates the Long-term memory (aka Meta-Buffer).\n\nWe run the agent a second time for another example of the 24-game.\n\nThis time the agent re-used the previously generated thought template and did not distill a new one for deriving the solution.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"03_buffer_of_thought.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","theme":"lux","title-block-banner":true,"title":"Buffer of Thoughts (BoT)","description":"This blog delves into the implementation of an agentic framework leveraging LangGraph’s Long-term memory feature. It demonstrates how this capability enhances the BoT agent’s ability to reason and solve complex problems by retaining and utilizing contextual information over time. Practical examples showcase the potential of LangGraph for building advanced, memory-augmented LLM agents.","author":"Oliver Pfante","date":"2025-01-26","categories":["agentic","code"],"image":"bot_agent.webp","jupyter":"python3","bibliography":["../references.bibtex"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}
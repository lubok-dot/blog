{
  "hash": "608571158105626563ab04823a1f7bb4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Tustin's Bilinear Transform\ndescription: 'This blog details the derivation of Ordinary Differentail Equation (ODE) time discretization using Tustin''s Bilinear Transform, focusing on understanding the S4 model construction.'\nauthor: Oliver Pfante\ndate: '2024-06-04'\ncategories:\n  - math\n  - code\nimage: fancy_ode.webp\ntoc: true\n---\n\nWe derive the ODE time discretization using [Tustin's Bilinear Transform](https://en.wikipedia.org/wiki/Bilinear_transform) @Tustin. This method is applied in the derivation of the S4 model @S4. While both the original publication @S4 and the blog [The Annotated S4](https://srush.github.io/annotated-s4/) @AnnotatedS4 present the final formulas obtained from Tustin's Bilinear Transform applied to the ODE of the state-space model, they do not provide the derivation process. Although the derivation of the discretized ODE from the continuous-time equations is not essential to understanding the construction of the S4 model, I sought a deeper understanding. Unfortunately, I could not find a free online version of Tustin's original publication from 1957. Therefore, I attempted to derive the discretization myself. This blog details that derivation.\n\n## Laplace Transform & $\\Delta$-Sampling\n\nWe define the [*unilateral Laplace Transform $\\mathcal L$*](https://en.wikipedia.org/wiki/Z-transform#Unilateral_Z-transform) of a sufficiently well behaved function defined on the real half-line $\\mathbb R$ of non-negative numbers as\n\n$$\n\\mathcal L(f)(s) = \\int_{0}^{\\infty} f(t) e^{- s t} \\, dt\n$$\n\nfor some $s \\in \\mathbb C$. Suppose, $f: \\mathbb N \\rightarrow \\mathbb R$ to be an absolute convergent series. We define the *Discrete time Laplace Transform* $\\mathcal L^D$ as\n\n$$\n\\mathcal L^D(f)(s) = \\sum_{n=0}^{\\infty} f(n) e^{ - s n}\n$$\n\nfor some $s \\in \\mathbb C$. If we substitute \n\n$$\nz = e^{s}\n$$\n\nwe get the [*unilateral Z-transform* $\\mathcal Z$](https://en.wikipedia.org/wiki/Z-transform#Unilateral_Z-transform) which is defined as\n\n$$\n\\mathcal Z(f)(z) = \\sum_{n=0}^{\\infty} f(n) z^{ -n}\n$$\n\nGiven a function $f$ on $\\mathbb R_{\\geq 0}$ and some *step size* $\\Delta > 0$, we define the $\\Delta$-sampling $\\mathcal S^\\Delta$ of $f$ as the corresponding discrete function on $\\mathbb N$\n\n$$\n\\mathcal S^\\Delta(f)(n) = f(n\\Delta) \\, .\n$$\n\nFor some $f$ on $\\mathbb R_{\\geq 0}$ we have\n\n\\begin{align*}\n\\mathcal L^D \\circ \\mathcal S^\\Delta(f)(s) &= \\sum_{n=0}^{\\infty} S^\\Delta(f)(n) e^{ - s n} \\\\\n&= \\sum_{n=0}^{\\infty} f(n\\Delta) e^{ - s n} = \\sum_{n=0}^{\\infty} f(n \\Delta) z^{-n}\n\\end{align*}\n\nThe Laplace Transform has several [interesting properties](https://en.wikipedia.org/wiki/Laplace_transform#Properties_and_theorems). It is a linear map, which follows immediatly from the linearity of integration, and it translates the derivative into a product. That is, for a differentiable funciton $f$ on $\\mathbb R_{\\geq 0}$ we have\n\n$$\n\\mathcal L (\\dot f)(s) = s \\mathcal L (f)(s) - f(0) \n$$\n\n## Bilinear Transform\n\nWe define the [*Bilinear Transform*](https://en.wikipedia.org/wiki/Bilinear_transform#Discrete-time_approximation) from the $s$-plane onto the $z$-plane as the map\n\n\\begin{align*}\ns &= \\log (z) \\\\\n  &= 2 \\left( \\dfrac{z - 1}{z + 1} + \\dfrac{1}{3} \\left( \\dfrac{z - 1}{z + 1} \\right)^3 + \\ldots \\right) \\\\\n  &\\approx 2 \\dfrac{z - 1}{z + 1}\n\\end{align*}\n\nThat is, it is the first-order rational approximation to the natural logarithm which maps the $z$-variable of the $\\mathcal Z$-transform back onto the $s$-variable of the $\\mathcal L$-transform.\n\n## State Space Models\n\nOur final interest is devoted to the [S4 model](https://srush.github.io/annotated-s4/) which considers a [*State Space Model (SSM)*](https://en.wikipedia.org/wiki/State-space_representation). It is a $1$-dimensional input signal $u(t)$ onto an $N$-dimensional latent signal $x(t)$ which is then projected onto a $1$-dimensional output variable $y(t)$.\n\n\\begin{align*}\n\\dot x(t) &= A x(t) + B u(t) \\\\\ny(t) &= C x(t) + D u(t)\n\\end{align*}\n\nFor some stationary (i.e., non time-dependent) matrices $A \\in \\mathbb R^{N \\times N}$, $B \\in \\mathbb R^{N \\times 1}$, $C \\in \\mathbb R^{1 \\times N}$, and $D \\in \\mathbb D^{1 \\times 1}$. The notation $\\mathbb R^{1 \\times N}$ and $\\mathbb R^{N \\times 1}$ denotes a row and a column vector, respectively. As in the derivation of the S4 model, we set $D = 0$.\n\n## Discrete Time\n\nInstead of a time-continues input signal $u(t)$, we have a discrete time-series $u_0, u_1, u_2, \\ldots$ sampled at some frequency $\\frac{1}{T}$ for some *step-size* $\\Delta > 0$. Hence, we must discretize the SSM. We consider the discrete time-series $u_0, u_1, u_2, \\ldots$ as being $\\Delta$-sampled from a continius function $u:\\mathbb R_{\\geq 0} \\rightarrow \\mathbb R$. Thus, $u_n = \\mathcal S^\\Delta(u)(n) = u(n \\Delta)$. Similarly, we have $x_0, x_1, x_2, \\ldots$ as being $\\Delta$-sampled from the solution of the ODE $x:\\mathbb R_{\\geq 0} \\rightarrow \\mathbb R$. Then, $x_n = \\mathcal S^\\Delta(x)(n) = x(n \\Delta)$. One approach to discretizing the SSM is the [*Euler Method*](https://en.wikipedia.org/wiki/Euler_method)\n\n$$\n\\dfrac{x(t + \\Delta) - x(t)}{\\Delta} = Ax(t) + Bu(t) \\, .\n$$\n\nIt is fast and simple to implement. However, Tustin's Bilinear Transform generally provides better accuracy for digital control and signal processing applications because it preserves the frequency characteristics of the original continuous-time system. We define the functions \n\n\\begin{align*}\n\\tilde x(t) &= x(\\Delta t) \\\\\n\\tilde u(t) &= u(\\Delta t) \n\\end{align*}\n\nfor all $t \\in \\mathbb R_{\\geq 0}$. Then, we obtain\n\n$$\n\\dot{\\tilde x} (t) = \\Delta \\dot x(\\Delta t) = \\Delta A x(\\Delta t) + \\Delta B u(\\Delta t) = \\Delta A \\tilde x(t) + \\Delta B \\tilde u(t)\n$$\n\nwhich implies\n\n$$\n\\dfrac{1}{\\Delta} \\dot{\\tilde x}(t) = A \\tilde x(t) + B \\tilde u(t)\n$$\n\nWe apply on the SSM the Laplace transform.\n\n\\begin{align*}\n\\dfrac{1}{\\Delta} \\mathcal L\\left(\\dot{\\tilde x}\\right)(s) = \\mathcal L\\left(\\dfrac{1}{\\Delta} \\dot{\\tilde x}\\right)(s) &= \\mathcal(A \\tilde x + B \\tilde u)(s) \\\\\n&= A \\mathcal L(\\tilde x)(s) + B \\mathcal L(\\tilde u)(s) \\\\\n\\end{align*}\n\nwhere we applied the linearity of the Laplace transform. Assuming $x(0) = 0$ we get\n\n$$\n\\mathcal L(\\dot{\\tilde x})(s) = s \\mathcal L(\\tilde x)(s)\n$$\n\nwhich yields\n\n$$\n\\dfrac{s}{\\Delta} \\mathcal L(\\dot{\\tilde x})(s) = A \\mathcal L(\\tilde x)(s) + B \\mathcal L(\\tilde u)(s) \\, .\n$$\n\nTo discretize the SSM we apply the following substitutions\n\n\\begin{align*}\n    \\tilde x &\\mapsto \\mathcal S^1(\\tilde x) = S^\\Delta(x) \\\\\n    \\tilde u &\\mapsto \\mathcal S^1(\\tilde u) = S^\\Delta(u) \\\\\n    \\mathcal L &\\mapsto \\mathcal L^D\n\\end{align*}\n\nRemember, $\\mathcal L^D$ is the discrete Laplace Transform, i.e., the $\\mathcal Z$-Transform in the $s$-space. These substitutions yield\n\n\\begin{align*}\n    \\dfrac{s}{\\Delta} \\left(\\mathcal L^D \\circ S^\\Delta(x)\\right)(s) = A \\left(\\mathcal L^D \\circ S^\\Delta(x) \\right)(s) + B \\left( \\mathcal L^D \\circ S^\\Delta(x) \\right)(s) \n\\end{align*}\n\nIf we apply the substitution $s = 2\\dfrac{z - 1}{z + 1}$ from the Bilinear Transform, and remember\n\n$$\n\\mathcal L^D \\circ \\mathcal S^\\Delta(f)(s) = \\sum_{n=0}^{\\infty} f(n \\Delta) z^{-n}\n$$\n\nfor any $f: \\mathbb R \\rightarrow \\mathbb R$, we get\n\n\\begin{align*}\n& \\dfrac{2}{\\Delta} \\dfrac{z - 1}{z + 1} \\sum_{n = 0}^{\\infty} x_n z^{-n} = A \\sum_{n = 0}^{\\infty} x_n z^{-n} + B \\sum_{n = 0}^{\\infty} u_n z^{-n} \\\\\n\\iff & \\dfrac{2}{\\Delta} \\left(\\sum_{n = 0}^{\\infty} x_n z^{-n + 1} - \\sum_{n = 0}^{\\infty} x_n z^{-n} \\right) \\\\\n& = A \\left(\\sum_{n = 0}^{\\infty} x_n z^{-n + 1} + \\sum_{n = 0}^{\\infty} x_n z^{-n} \\right) + B \\left(\\sum_{n = 0}^{\\infty} u_n z^{-n + 1} + \\sum_{n = 0}^{\\infty} u_n z^{-n} \\right) \\\\\n\\iff & \\dfrac{2}{\\Delta} \\left(x_0 z + \\sum_{n = 0}^{\\infty} (x_{n + 1} - x_n)   z^{-n} \\right) \\\\\n& = A \\left(x_0 z + \\sum_{n = 0}^{\\infty} (x_{n + 1} + x_n) z^{-n} \\right) + B \\left(u_0 z + \\sum_{n = 0}^{\\infty} (u_{n + 1} + u_n)   z^{-n} \\right) \\\\\n\\iff & \\dfrac{2}{\\Delta} (x_{n + 1} - x_n) = A(x_{n + 1} + x_n) + B(u_{n + 1} + u_n) \n\\end{align*}\n\nfor all $n \\in \\mathbb N$ where we assumed that $x_0 = 0$ and $u_0 = 0$. The last equivalence follows from $\\{z^{-n}| n \\in \\mathbb N \\}$ being a set of linear independent complex functions. Solving the equation for $x_{n + 1}$ and assuming the approximantion $u_{n + 1} \\approx u_n$ yields\n\n\\begin{align*}\nx_{n + 1}   &= \\left(\\dfrac{2}{\\Delta} - A \\right)^{-1}\\left(\\dfrac{2}{\\Delta} + A \\right) x_n + 2 \\left(\\dfrac{2}{\\Delta} - A \\right)^{-1} B u_{n + 1} \\\\\n            &= \\left(I_n - \\dfrac{\\Delta}{2} A \\right)^{-1}\\left(I_n + \\dfrac{\\Delta}{2} A \\right) x_n + \\left(I_n - \\dfrac{\\Delta}{2} A\\right)^{-1} \\Delta  B u_{n + 1} \\\\\n            &= \\overline A x_n + \\overline B u_{n + 1}\n\\end{align*}\n\nwith the $n$-dimensional identity matrix $I_n$ and\n\n\\begin{align*}\n\\overline A &= \\left(I_n - \\dfrac{\\Delta}{2} A \\right)^{-1}\\left(I_n + \\dfrac{\\Delta}{2} A \\right) \\\\\n\\overline B &= \\left(I_n - \\dfrac{\\Delta}{2} A \\right)^{-1}\\Delta B\n\\end{align*}\nsuch that the full discretized SSM reads as\n\n\\begin{align*}\n    x_{n + 1} &= \\overline A x_n + \\overline B u_{n + 1} \\\\\n    y_{n + 1} &= \\overline C x_{n + 1} \n\\end{align*}\n\nwith $\\overline C = C$.\n\n## Example\n\nWe compare the quality of the Tustinâ€™s Bilinear Transform with the Euler discretization and the Initial Value Solver from scipy. The later one we consider as ground truth solution and check to what extent the Tustin's and Euler's method approximate it.\n\n::: {#f56652d1 .cell execution_count=1}\n`````````` {.python .cell-code}\nimport jax\nimport jax.numpy as np\nfrom jax.numpy.linalg import inv\nfrom scipy.integrate import solve_ivp\nimport matplotlib.pyplot as plt\nfrom celluloid import Camera\n\n\nclass IVP_Solvers:\n\n    def __init__(self, A, B, C, u, T, step, x0):\n        \"\"\"\n        Initializes the IVP_Solvers class with the given parameters.\n\n        Args:\n            A (numpy.ndarray): The state transition matrix with shape (N, N).\n            B (numpy.ndarray): The input matrix with shape (N, 1).\n            C (numpy.ndarray): The output matrix with shape (1, N).\n            u (function): The input signal function.\n            T (float): The total time of the simulation.\n            step (float): The time step size.\n            x0 (numpy.ndarray): The initial state vector with shape (N,).\n\n        Returns:\n            None\n        \"\"\"\n        self.A = A\n        self.B = B\n        self.C = C\n        self.T = T\n        self.u = u\n        self.step = step\n        self.x0 = x0\n        self.n = A.shape[0]\n        self.ts = np.linspace(0, self.T, int(\n            self.T / self.step), endpoint=True)\n\n    def discretize(self):\n        \"\"\"\n        Discretizes the system using the Tustin's method. Follows the implementation\n        of the AnnotatedS4 blog post (https://srush.github.io/annotated-s4/).\n\n        Returns:\n            Ab (ndarray): The discretized A matrix.\n            Bb (ndarray): The discretized B matrix.\n        \"\"\"\n        I = np.eye(self.n)\n        BL = inv(I - (self.step / 2.0) * self.A)\n        Ab = BL @ (I + (self.step / 2.0) * self.A)\n        Bb = (BL * self.step) @ self.B\n        return Ab, Bb\n\n    def tustin(self):\n        \"\"\"\n        Simulates the system using the Tustin's method.\n\n        Returns:\n            y (ndarray): The output vector of shape (K, 1) where K is the number of time steps.\n        \"\"\"\n        Ab, Bb = self.discretize()\n\n        def step(x_k_1, u_k):\n            \"\"\"\n            Step function for the Tustin's method.\n\n            Args:\n                x_k_1 (ndarray): The previous state vector of shape (N,).\n                u_k (ndarray): The input vector of shape (1,).\n\n            Returns:\n                x_k (ndarray): The current state vector of shape (N,).\n                y_k (ndarray): The output vector of shape (1,).\n            \"\"\"\n            x_k = Ab @ x_k_1 + Bb @ u_k\n            y_k = self.C @ x_k\n            return x_k, y_k\n\n        return jax.lax.scan(step, self.x0, self.u(self.ts)[:, np.newaxis])[1]\n\n    def euler(self):\n        \"\"\"\n        Simulates the system using the Euler method.           \n        \"\"\"\n        def step(x_k_1, u_k):\n            x_k = x_k_1 + self.step * (self.A @ x_k_1 + self.B @ u_k)\n            y_k = self.C @ x_k\n            return x_k, y_k\n\n        return jax.lax.scan(step, self.x0, self.u(self.ts)[:, np.newaxis])[1]\n\n    def ode_solver(self):\n        \"\"\"\n        Solves the ordinary differential equation (ODE) using the given parameters.\n\n        This function uses the `solve_ivp` function from the `scipy.integrate` module \n        to numerically solve the ODE defined by the right-hand side function `f`. The \n        ODE is given by:\n\n        dx/dt = A @ x + B[:, 0] * u(t)\n\n        where `x` is the state vector, `t` is the time, `A` is the state transition matrix, \n        `B` is the input matrix, `u(t)` is the input signal function, and `C` is the output \n        matrix.\n\n        Returns:\n            numpy.ndarray: The solution of the ODE at the specified time points of shape \n            (1, K) where K is the number of time steps.\n        \"\"\"\n        def f(t, x):\n            return self.A @ x + self.B[:, 0] * self.u(t)\n\n        sol = solve_ivp(f, (0, self.T), self.x0, t_eval=self.ts)\n        return self.C @ sol.y\n``````````\n:::\n\n\nWe pick the same example from the @AnnotatedS4 and consider a SSM which describes a one-dimensional [moving object](https://en.wikipedia.org/wiki/State-space_representation#Moving_object_example). Newton's laws of motion for an object moving horizontally on a plane and attached to a wall with a spring read\n\n$$\nm \\ddot{y}(t) = u(t) - b \\dot{y}(t) - k y(t)\n$$\n\nwhere $y(t)$ is the position, $\\dot{y}(t)$ is the velocity, $\\ddot{y}(t)$ is the acceleration, $u(t)$ is the applied force, $b$ is the viscous friction coefficient, $k$ is the spring constant, and $m$ is the mass of the object. This second order linear differential equation can be rewritten as SSM \n\n\\begin{align*}\nx(t) &= \\begin{bmatrix} y(t)\\\\\n \\dot{y}(t) \\end{bmatrix} \\\\ \\\\\nA &= \\begin{bmatrix}\n0 & 1 \\\\\n-\\dfrac{k}{m} & -\\dfrac{b}{m}\n\\end{bmatrix} \\\\ \\\\\nB &= \\begin{bmatrix}\n0 \\\\\n\\dfrac{1}{m}\n\\end{bmatrix} \\\\ \\\\\nC &= \\begin{bmatrix} 1 & 0 \\end{bmatrix}\n\\end{align*}\n\n::: {#311b09ea .cell execution_count=2}\n``` {.python .cell-code}\ndef moving_object(k, b, m):\n    \"\"\"\n    Generate the state matrices for a moving object.\n\n    Parameters:\n        k (float): The spring constant.\n        b (float): The damping coefficient.\n        m (float): The mass of the object.\n\n    Returns:\n        A (numpy.ndarray): The state transition matrix.\n        B (numpy.ndarray): The input matrix.\n        C (numpy.ndarray): The output matrix.\n    \"\"\"\n    A = np.array([[0, 1], [-k / m, -b / m]])\n    B = np.array([[0], [1.0 / m]])\n    C = np.array([[1.0, 0]])\n    return A, B, C\n```\n:::\n\n\nThe force $u(t)$ is the same as in @AnnotatedS4.\n\n::: {#2a9916fa .cell execution_count=3}\n``` {.python .cell-code}\ndef force(t):\n    \"\"\"\n    Generate an example force signal function.\n\n    Parameters:\n        t (float): The time at which the force signal is evaluated.\n\n    Returns:\n        float: The force signal value at the given time.\n    \"\"\"\n    x = np.sin(10 * t)\n    return x * (x > 0.5)\n```\n:::\n\n\nThis gives us the following system:\n\n::: {#61cbd267 .cell execution_count=4}\n``` {.python .cell-code}\ndef render_example(k=40, b=5, m=1, T=np.pi):\n    \"\"\"\n    Renders an example of the Tustin's method.\n    \"\"\"\n    ssm = IVP_Solvers(*moving_object(k, b, m), u=force,\n                      T=T, step=1e-1, x0=np.zeros((2,)))\n\n    y_tustin = ssm.tustin()[:, 0]\n    y_euler = ssm.euler()[:, 0]\n\n    ssm_true = IVP_Solvers(*moving_object(k, b, m), u=force,\n                           T=T, step=1e-3, x0=np.zeros((2,)))\n    y_true = ssm_true.ode_solver()[0, :]\n\n    fig = plt.figure(figsize=(10, 5))\n    camera = Camera(fig)\n    ax = fig.add_subplot(111)\n    ax.set_xlabel('Time (s)')\n    ax.set_ylabel('Position (m)')\n\n    # Animate plot over time\n    ratio = int(ssm.step / ssm_true.step)\n    for k in range(0, len(ssm.ts)):\n        ax.plot(ssm.ts[:k], y_tustin[:k], color='blue', linestyle='--',\n                label='Tustin position $y_k$')\n        ax.plot(ssm.ts[:k], y_euler[:k], color='red', linestyle='--',\n                label='Euler position $y_k$')\n        ax.plot(ssm_true.ts[:k*ratio], y_true[:k*ratio], color='green',\n                label='True position $y_k$', linewidth=2, alpha=0.5)\n        if not k:\n            ax.legend()\n        camera.snap()\n    anim = camera.animate()\n    anim.save(\"line.gif\", dpi=150, writer=\"imagemagick\")\n\n\nrender_example()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nMovieWriter imagemagick unavailable; using Pillow instead.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-2.png){width=840 height=429}\n:::\n:::\n\n\n![Comparison of Tustin's and the Euler methods for the moving object example.](line.gif)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}
[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Miscellaneous",
    "section": "",
    "text": "Hello and welcome to my blog!\nI’m a mathematician by training, with a journey that has taken me from theoretical research to the dynamic world of data science. Over more than a decade, I’ve gained experience across academia and the life sciences industry, working at every stage of drug development. My career has spanned using AI in pre-clinical research and drug discovery, leveraging real-world data to streamline clinical trials, and enhancing the manufacturing of established medicines. Today, I contribute to these efforts as part of a leading generic drug company in Basel, Switzerland.\nMy passions include mathematics, generative AI, writing, and art. My background as a researcher has left me with an intrinsic motivation for diving deep into the latest scientific articles, particularly in machine learning. I enjoy exploring these concepts by re-implementing models from scratch, relying solely on the descriptions provided in the papers. This blog is my space to share these experiments, along with some of my personal creative endeavors—whether that’s poetry, short stories, or anything else that inspires me.\nThank you for stopping by!\nOliver"
  },
  {
    "objectID": "posts/tustins_method/index.html",
    "href": "posts/tustins_method/index.html",
    "title": "Tustin’s Bilinear transform",
    "section": "",
    "text": "Updated on January 28, 2025: A derivation of the time-discrete ODE using the Trapezoidal Rule for approximating derivatives is provided in the Appendix of (Gu 2023).\nWe derive the ODE time discretization using Tustin’s Bilinear transform (Tustin 1947). This method is applied in the derivation of the S4 model (Gu, Goel, and Ré 2021). While both the original publication (Gu, Goel, and Ré 2021) and the blog The Annotated S4 (Gu, Goel, and Ré Accessed: 2024-06-06) present the final formulas obtained from Tustin’s Bilinear transform applied to the ODE of the state-space model, they do not provide the derivation process. Although the derivation of the discretized ODE from the continuous-time equations is not essential to understanding the construction of the S4 model, I sought a deeper understanding. Unfortunately, I could not find a free online version of Tustin’s original publication from 1947. Therefore, I attempted to derive the discretization myself. This blog details that derivation."
  },
  {
    "objectID": "posts/tustins_method/index.html#laplace-transform-delta-sampling",
    "href": "posts/tustins_method/index.html#laplace-transform-delta-sampling",
    "title": "Tustin’s Bilinear transform",
    "section": "Laplace transform & \\(\\Delta\\)-Sampling",
    "text": "Laplace transform & \\(\\Delta\\)-Sampling\nThe unilateral Laplace transform \\(\\mathcal L(f)\\) of a sufficiently well behaved function \\(f: \\mathbb R_{\\geq 0} \\rightarrow \\mathbb R\\) on the real half-line of non-negative numbers is defined as\n\\[\n\\mathcal L(f)(s) = \\int_{0}^{\\infty} f(t) e^{- s t} \\, dt\n\\]\nfor some \\(s \\in \\mathbb C\\). Suppose, \\(f: \\mathbb N \\rightarrow \\mathbb R\\) to be an absolute convergent series. We define the Discrete time Laplace transform \\(\\mathcal L^D(f)\\) of \\(f\\) as\n\\[\n\\mathcal L^D(f)(s) = \\sum_{n=0}^{\\infty} f(n) e^{ - s n}\n\\]\nfor some \\(s \\in \\mathbb C\\). If we substitute\n\\[\nz = e^{s}\n\\]\nwe get the unilateral Z-transform \\(\\mathcal Z(f)\\) of \\(f\\) which is defined as\n\\[\n\\mathcal Z(f)(z) = \\sum_{n=0}^{\\infty} f(n) z^{ -n} \\, .\n\\]\nGiven a function \\(f\\) on \\(\\mathbb R_{\\geq 0}\\) and some step size \\(\\Delta &gt; 0\\), we define the \\(\\Delta\\)-sampling \\(\\mathcal S^\\Delta(f)\\) of \\(f\\) as the discrete function\n\\[\n\\mathcal S^\\Delta(f)(n) = f(n\\Delta)\n\\]\nfor all \\(n \\in \\mathbb N\\). For some \\(f\\) on \\(\\mathbb R_{\\geq 0}\\) we have\n\\[\\begin{align*}\n\\mathcal L^D \\circ \\mathcal S^\\Delta(f)(s) &= \\sum_{n=0}^{\\infty} S^\\Delta(f)(n) e^{ - s n} \\\\\n&= \\sum_{n=0}^{\\infty} f(n\\Delta) e^{ - s n} = \\sum_{n=0}^{\\infty} f(n \\Delta) z^{-n}\n\\end{align*}\\]\nThe Laplace transform has several interesting properties. It is a linear map. This follows immediately from the linearity of integration. It translates the derivative into a product. That is, for a differentiable function \\(f\\) on \\(\\mathbb R_{\\geq 0}\\) we have\n\\[\n\\mathcal L (\\dot f)(s) = s \\mathcal L (f)(s) - f(0)\n\\]"
  },
  {
    "objectID": "posts/tustins_method/index.html#bilinear-transform",
    "href": "posts/tustins_method/index.html#bilinear-transform",
    "title": "Tustin’s Bilinear transform",
    "section": "Bilinear transform",
    "text": "Bilinear transform\nWe define the Bilinear transform from the \\(z\\)-plane to the \\(s\\)-plane as the map\n\\[\\begin{align*}\ns &= \\log (z) \\\\\n  &= 2 \\left( \\dfrac{z - 1}{z + 1} + \\dfrac{1}{3} \\left( \\dfrac{z - 1}{z + 1} \\right)^3 + \\ldots \\right) \\\\\n  &\\approx 2 \\dfrac{z - 1}{z + 1}\n\\end{align*}\\]\nThat is, it is the first-order rational approximation to the natural logarithm which maps the \\(z\\)-variable of the \\(\\mathcal Z\\)-transform back onto the \\(s\\)-variable of the Laplace transform."
  },
  {
    "objectID": "posts/tustins_method/index.html#state-space-models",
    "href": "posts/tustins_method/index.html#state-space-models",
    "title": "Tustin’s Bilinear transform",
    "section": "State Space Models",
    "text": "State Space Models\nOur final interest is devoted to the S4 model which considers a State Space Model (SSM). It is a \\(1\\)-dimensional input signal \\(u(t)\\) onto an \\(N\\)-dimensional latent signal \\(x(t)\\) which is then projected onto a \\(1\\)-dimensional output variable \\(y(t)\\)\n\\[\\begin{align*}\n\\dot x(t) &= A x(t) + B u(t) \\\\\ny(t) &= C x(t) + D u(t)\n\\end{align*}\\]\nfor some stationary (i.e., non time-dependent) matrices \\(A \\in \\mathbb R^{N \\times N}\\), \\(B \\in \\mathbb R^{N \\times 1}\\), \\(C \\in \\mathbb R^{1 \\times N}\\), and \\(D \\in \\mathbb D^{1 \\times 1}\\). The notation \\(\\mathbb R^{1 \\times N}\\) and \\(\\mathbb R^{N \\times 1}\\) denotes a row and a column vector, respectively. As in the derivation of the S4 model, we set \\(D = 0\\)."
  },
  {
    "objectID": "posts/tustins_method/index.html#discrete-time",
    "href": "posts/tustins_method/index.html#discrete-time",
    "title": "Tustin’s Bilinear transform",
    "section": "Discrete Time",
    "text": "Discrete Time\nInstead of a time-continues input signal \\(u(t)\\), we have a discrete time-series \\(u_0, u_1, u_2, \\ldots\\) sampled at some frequency \\(\\frac{1}{\\Delta}\\) for some step-size \\(\\Delta &gt; 0\\). Hence, we must discretize the SSM. We consider the discrete time-series \\(u_0, u_1, u_2, \\ldots\\) as being \\(\\Delta\\)-sampled from a continuous function \\(u:\\mathbb R_{\\geq 0} \\rightarrow \\mathbb R\\). Thus, \\(u_n = \\mathcal S^\\Delta(u)(n) = u(n \\Delta)\\). Similarly, we have \\(x_0, x_1, x_2, \\ldots\\) as being \\(\\Delta\\)-sampled from the solution of the ODE \\(x:\\mathbb R_{\\geq 0} \\rightarrow \\mathbb R\\). Then, \\(x_n = \\mathcal S^\\Delta(x)(n) = x(n \\Delta)\\). One approach to discretizing the SSM is the Euler Method\n\\[\n\\dfrac{x(t + \\Delta) - x(t)}{\\Delta} = Ax(t) + Bu(t) \\, .\n\\]\nIt is fast and simple to implement. However, Tustin’s Bilinear transform generally provides better accuracy for digital control and signal processing applications because it preserves the frequency characteristics of the original continuous-time system “Bilinear Transform” (Accessed: 2024-06-09). We define the functions\n\\[\\begin{align*}\n\\tilde x(t) &= x(\\Delta t) \\\\\n\\tilde u(t) &= u(\\Delta t)\n\\end{align*}\\]\nfor all \\(t \\in \\mathbb R_{\\geq 0}\\). Then, we obtain\n\\[\n\\dot{\\tilde x} (t) = \\Delta \\dot x(\\Delta t) = \\Delta A x(\\Delta t) + \\Delta B u(\\Delta t) = \\Delta A \\tilde x(t) + \\Delta B \\tilde u(t)\n\\]\nwhich implies\n\\[\n\\dfrac{1}{\\Delta} \\dot{\\tilde x}(t) = A \\tilde x(t) + B \\tilde u(t)\n\\]\nWe apply to the SSM the Laplace transform.\n\\[\\begin{align*}\n\\dfrac{1}{\\Delta} \\mathcal L\\left(\\dot{\\tilde x}\\right)(s) = \\mathcal L\\left(\\dfrac{1}{\\Delta} \\dot{\\tilde x}\\right)(s) &= \\mathcal(A \\tilde x + B \\tilde u)(s) \\\\\n&= A \\mathcal L(\\tilde x)(s) + B \\mathcal L(\\tilde u)(s) \\\\\n\\end{align*}\\]\nwhere we applied the linearity of the Laplace transform. Assuming \\(x(0) = 0\\) we get\n\\[\n\\mathcal L(\\dot{\\tilde x})(s) = s \\mathcal L(\\tilde x)(s)\n\\]\nwhich yields\n\\[\n\\dfrac{s}{\\Delta} \\mathcal L(\\tilde x)(s) = A \\mathcal L(\\tilde x)(s) + B \\mathcal L(\\tilde u)(s) \\, .\n\\]\nTo discretize the SSM we apply the following substitutions\n\\[\\begin{align*}\n    \\tilde x &\\mapsto \\mathcal S^1(\\tilde x) = S^\\Delta(x) \\\\\n    \\tilde u &\\mapsto \\mathcal S^1(\\tilde u) = S^\\Delta(u) \\\\\n    \\mathcal L &\\mapsto \\mathcal L^D\n\\end{align*}\\]\nRemember, \\(\\mathcal L^D\\) is the discrete Laplace transform, i.e., the \\(\\mathcal Z\\)-transform in the \\(s\\)-space. These substitutions yield\n\\[\\begin{align*}\n    \\dfrac{s}{\\Delta} \\left(\\mathcal L^D \\circ S^\\Delta(x)\\right)(s) = A \\left(\\mathcal L^D \\circ S^\\Delta(x) \\right)(s) + B \\left( \\mathcal L^D \\circ S^\\Delta(x) \\right)(s)\n\\end{align*}\\]\nIf we apply the substitution \\(s = 2\\dfrac{z - 1}{z + 1}\\) from the Bilinear transform and remember\n\\[\n\\mathcal L^D \\circ \\mathcal S^\\Delta(f)(s) = \\sum_{n=0}^{\\infty} f(n \\Delta) z^{-n}\n\\]\nfor any \\(f: \\mathbb R \\rightarrow \\mathbb R\\), we get\n\\[\\begin{align*}\n& \\dfrac{2}{\\Delta} \\dfrac{z - 1}{z + 1} \\sum_{n = 0}^{\\infty} x_n z^{-n} = A \\sum_{n = 0}^{\\infty} x_n z^{-n} + B \\sum_{n = 0}^{\\infty} u_n z^{-n} \\\\\n\\iff & \\dfrac{2}{\\Delta} \\left(\\sum_{n = 0}^{\\infty} x_n z^{-n + 1} - \\sum_{n = 0}^{\\infty} x_n z^{-n} \\right) \\\\\n& = A \\left(\\sum_{n = 0}^{\\infty} x_n z^{-n + 1} + \\sum_{n = 0}^{\\infty} x_n z^{-n} \\right) + B \\left(\\sum_{n = 0}^{\\infty} u_n z^{-n + 1} + \\sum_{n = 0}^{\\infty} u_n z^{-n} \\right) \\\\\n\\iff & \\dfrac{2}{\\Delta} \\left(x_0 z + \\sum_{n = 0}^{\\infty} (x_{n + 1} - x_n)   z^{-n} \\right) \\\\\n& = A \\left(x_0 z + \\sum_{n = 0}^{\\infty} (x_{n + 1} + x_n) z^{-n} \\right) + B \\left(u_0 z + \\sum_{n = 0}^{\\infty} (u_{n + 1} + u_n)   z^{-n} \\right) \\\\\n\\iff & \\dfrac{2}{\\Delta} (x_{n + 1} - x_n) = A(x_{n + 1} + x_n) + B(u_{n + 1} + u_n)\n\\end{align*}\\]\nfor all \\(n \\in \\mathbb N\\) where we assumed that \\(x_0 = 0\\) and \\(u_0 = 0\\). The last equivalence follows from \\(\\{z^{-n}| n \\in \\mathbb N \\}\\) being a set of linear independent complex functions. Solving the equation for \\(x_{n + 1}\\) and assuming the approximation \\(u_{n + 1} \\approx u_n\\) yields\n\\[\\begin{align*}\nx_{n + 1}   &= \\left(\\dfrac{2}{\\Delta} - A \\right)^{-1}\\left(\\dfrac{2}{\\Delta} + A \\right) x_n + 2 \\left(\\dfrac{2}{\\Delta} - A \\right)^{-1} B u_{n + 1} \\\\\n            &= \\left(I_n - \\dfrac{\\Delta}{2} A \\right)^{-1}\\left(I_n + \\dfrac{\\Delta}{2} A \\right) x_n + \\left(I_n - \\dfrac{\\Delta}{2} A\\right)^{-1} \\Delta  B u_{n + 1} \\\\\n            &= \\overline A x_n + \\overline B u_{n + 1}\n\\end{align*}\\]\nwith the \\(n\\)-dimensional identity matrix \\(I_n\\) and\n\\[\\begin{align*}\n\\overline A &= \\left(I_n - \\dfrac{\\Delta}{2} A \\right)^{-1}\\left(I_n + \\dfrac{\\Delta}{2} A \\right) \\\\\n\\overline B &= \\left(I_n - \\dfrac{\\Delta}{2} A \\right)^{-1}\\Delta B\n\\end{align*}\\] such that the full discretized SSM reads as\n\\[\\begin{align*}\n    x_{n + 1} &= \\overline A x_n + \\overline B u_{n + 1} \\\\\n    y_{n + 1} &= \\overline C x_{n + 1}\n\\end{align*}\\]\nwith \\(\\overline C = C\\)."
  },
  {
    "objectID": "posts/tustins_method/index.html#example",
    "href": "posts/tustins_method/index.html#example",
    "title": "Tustin’s Bilinear transform",
    "section": "Example",
    "text": "Example\nWe compare the quality of Tustin’s Bilinear transform with the Euler discretization and the Initial Value Solver from SciPy. The latter is considered the ground truth solution, and we examine how well Tustin’s and Euler’s methods approximate it.\n\nimport jax\nimport jax.numpy as np\nfrom jax.numpy.linalg import inv\nfrom scipy.integrate import solve_ivp\n\n\nclass IVP_Solvers:\n\n    def __init__(self, A, B, C, u, T, step, x0):\n        \"\"\"\n        Initializes the IVP_Solvers class with the given parameters.\n\n        Args:\n            A (numpy.ndarray): The state transition matrix with shape (N, N).\n            B (numpy.ndarray): The input matrix with shape (N, 1).\n            C (numpy.ndarray): The output matrix with shape (1, N).\n            u (function): The input signal function.\n            T (float): The total time of the simulation.\n            step (float): The time step size.\n            x0 (numpy.ndarray): The initial state vector with shape (N,).\n\n        Returns:\n            None\n        \"\"\"\n        self.A = A\n        self.B = B\n        self.C = C\n        self.T = T\n        self.u = u\n        self.step = step\n        self.x0 = x0\n        self.n = A.shape[0]\n        self.ts = np.linspace(0, self.T, int(\n            self.T / self.step), endpoint=True)\n\n    def discretize(self):\n        \"\"\"\n        Discretizes the system using the Tustin's method. Follows the implementation\n        of the AnnotatedS4 blog post (https://srush.github.io/annotated-s4/).\n\n        Returns:\n            Ab (ndarray): The discretized A matrix.\n            Bb (ndarray): The discretized B matrix.\n        \"\"\"\n        I = np.eye(self.n)\n        BL = inv(I - (self.step / 2.0) * self.A)\n        Ab = BL @ (I + (self.step / 2.0) * self.A)\n        Bb = (BL * self.step) @ self.B\n        return Ab, Bb\n\n    def tustin(self):\n        \"\"\"\n        Simulates the system using the Tustin's method.\n\n        Returns:\n            y (ndarray): The output vector of shape (K, 1) where K is the number of time steps.\n        \"\"\"\n        Ab, Bb = self.discretize()\n\n        def step(x_k_1, u_k):\n            \"\"\"\n            Step function for the Tustin's method.\n\n            Args:\n                x_k_1 (ndarray): The previous state vector of shape (N,).\n                u_k (ndarray): The input vector of shape (1,).\n\n            Returns:\n                x_k (ndarray): The current state vector of shape (N,).\n                y_k (ndarray): The output vector of shape (1,).\n            \"\"\"\n            x_k = Ab @ x_k_1 + Bb @ u_k\n            y_k = self.C @ x_k\n            return x_k, y_k\n\n        return jax.lax.scan(step, self.x0, self.u(self.ts)[:, np.newaxis])[1]\n\n    def euler(self):\n        \"\"\"\n        Simulates the system using the Euler method.           \n        \"\"\"\n        def step(x_k_1, u_k):\n            x_k = x_k_1 + self.step * (self.A @ x_k_1 + self.B @ u_k)\n            y_k = self.C @ x_k\n            return x_k, y_k\n\n        return jax.lax.scan(step, self.x0, self.u(self.ts)[:, np.newaxis])[1]\n\n    def ode_solver(self):\n        \"\"\"\n        Solves the ordinary differential equation (ODE) using the given parameters.\n\n        This function uses the `solve_ivp` function from the `scipy.integrate` module \n        to numerically solve the ODE defined by the right-hand side function `f`. The \n        ODE is given by:\n\n        dx/dt = A @ x + B[:, 0] * u(t)\n\n        where `x` is the state vector, `t` is the time, `A` is the state transition matrix, \n        `B` is the input matrix, `u(t)` is the input signal function, and `C` is the output \n        matrix.\n\n        Returns:\n            numpy.ndarray: The solution of the ODE at the specified time points of shape \n            (1, K) where K is the number of time steps.\n        \"\"\"\n        def f(t, x):\n            return self.A @ x + self.B[:, 0] * self.u(t)\n\n        sol = solve_ivp(f, (0, self.T), self.x0, t_eval=self.ts)\n        return self.C @ sol.y\n\nWe pick the same example from the (Gu, Goel, and Ré Accessed: 2024-06-06) and consider a SSM which describes a one-dimensional moving object. Newton’s laws of motion for an object moving horizontally on a plane and attached to a wall with a spring read as\n\\[\nm \\ddot{y}(t) = u(t) - b \\dot{y}(t) - k y(t)\n\\]\nwhere \\(y(t)\\) is the position, \\(\\dot{y}(t)\\) is the velocity, \\(\\ddot{y}(t)\\) is the acceleration, \\(u(t)\\) is the applied force, \\(b\\) is the viscous friction coefficient, \\(k\\) is the spring constant, and \\(m\\) is the mass of the object. This second order linear differential equation can be rewritten as SSM\n\\[\\begin{align*}\nx(t) &= \\begin{bmatrix} y(t)\\\\\n\\dot{y}(t) \\end{bmatrix} \\\\ \\\\\nA &= \\begin{bmatrix}\n0 & 1 \\\\\n-\\dfrac{k}{m} & -\\dfrac{b}{m}\n\\end{bmatrix} \\\\ \\\\\nB &= \\begin{bmatrix}\n0 \\\\\n\\dfrac{1}{m}\n\\end{bmatrix} \\\\ \\\\\nC &= \\begin{bmatrix} 1 & 0 \\end{bmatrix}\n\\end{align*}\\]\n\ndef moving_object(k, b, m):\n    \"\"\"\n    Generate the state matrices for a moving object.\n\n    Parameters:\n        k (float): The spring constant.\n        b (float): The damping coefficient.\n        m (float): The mass of the object.\n\n    Returns:\n        A (numpy.ndarray): The state transition matrix.\n        B (numpy.ndarray): The input matrix.\n        C (numpy.ndarray): The output matrix.\n    \"\"\"\n    A = np.array([[0, 1], [-k / m, -b / m]])\n    B = np.array([[0], [1.0 / m]])\n    C = np.array([[1.0, 0]])\n    return A, B, C\n\nThe force \\(u(t)\\) is the same as in (Gu, Goel, and Ré Accessed: 2024-06-06).\n\ndef force(t):\n    \"\"\"\n    Generate an example force signal function.\n\n    Parameters:\n        t (float): The time at which the force signal is evaluated.\n\n    Returns:\n        float: The force signal value at the given time.\n    \"\"\"\n    x = np.sin(10 * t)\n    return x * (x &gt; 0.5)\n\nThis gives us the following system:\n\nimport matplotlib.pyplot as plt\nfrom celluloid import Camera\n\n\ndef render_example(k=40, b=5, m=1, T=np.pi):\n    \"\"\"\n    Renders an example of the Tustin's method.\n    \"\"\"\n    ssm = IVP_Solvers(*moving_object(k, b, m), u=force,\n                      T=T, step=1e-1, x0=np.zeros((2,)))\n\n    y_tustin = ssm.tustin()[:, 0]\n    y_euler = ssm.euler()[:, 0]\n\n    ssm_true = IVP_Solvers(*moving_object(k, b, m), u=force,\n                           T=T, step=1e-3, x0=np.zeros((2,)))\n    y_true = ssm_true.ode_solver()[0, :]\n\n    fig = plt.figure(figsize=(10, 5))\n    camera = Camera(fig)\n    ax = fig.add_subplot(111)\n    ax.set_xlabel('Time (s)')\n    ax.set_ylabel('Position (m)')\n\n    # Animate plot over time\n    ratio = int(ssm.step / ssm_true.step)\n    for k in range(0, len(ssm.ts)):\n        ax.plot(ssm.ts[:k], y_tustin[:k], color='blue', linestyle='--',\n                label='Tustin position $y_k$')\n        ax.plot(ssm.ts[:k], y_euler[:k], color='red', linestyle='--',\n                label='Euler position $y_k$')\n        ax.plot(ssm_true.ts[:k*ratio], y_true[:k*ratio], color='green',\n                label='True position $y_k$', linewidth=2, alpha=0.5)\n        if not k:\n            ax.legend()\n        camera.snap()\n    anim = camera.animate()\n    anim.save(\"line.gif\", dpi=150, writer=\"imagemagick\")\n\n\nrender_example()\n\n\n\n\nComparison of Tustin’s and the Euler methods for the moving object example.\n\n\nOne can clearly read off the better approximation of the true solution by Tustin’s Bilinear transform compared to the Euler discretization."
  },
  {
    "objectID": "posts/tustins_method/index.html#references",
    "href": "posts/tustins_method/index.html#references",
    "title": "Tustin’s Bilinear transform",
    "section": "References",
    "text": "References\n\n\n“Bilinear Transform.” Accessed: 2024-06-09. Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/wiki/Bilinear_transform#Frequency_warping.\n\n\nGu, Albert. 2023. “Modeling Sequences with Structured State Spaces.” PhD thesis, Stanford University. https://purl.stanford.edu/mb976vf9362.\n\n\nGu, Albert, Karan Goel, and Christopher Ré. Accessed: 2024-06-06. “Annotated S4.” https://srush.github.io/annotated-s4/.\n\n\n———. 2021. “Efficiently Modeling Long Sequences with Structured State Spaces.” arXiv Preprint. https://arxiv.org/abs/2111.00396.\n\n\nTustin, Arnold. 1947. “A Method of Analysing the Behaviour of Linear Systems in Terms of Time Series.” Journal of the Institution of Electrical Engineers 94: 130."
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html",
    "href": "posts/agent_coder/01_agent_coder.html",
    "title": "Agent Coder",
    "section": "",
    "text": "AgentCoder is a multi-agent framework designed to enhance code generation by leveraging three distinct roles to streamline the coding and validation process. This implementation is directly derived from the paper “AgentCoder: Multi-Agent Code Generation with Effective Testing and Self-Optimization”(Huang et al. 2024), with some minor modifications to the prompts to optimize its functionality within LangGraph."
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html#setup",
    "href": "posts/agent_coder/01_agent_coder.html#setup",
    "title": "Agent Coder",
    "section": "Setup",
    "text": "Setup\n\n\n\nfrom langgraph.graph import StateGraph, END, START, MessagesState\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import (\n    ChatPromptTemplate,\n    MessagesPlaceholder,\n    PromptTemplate,\n)\nfrom langchain_core.output_parsers.string import StrOutputParser\nfrom pydantic import BaseModel, Field\nfrom typing import List, Annotated, Literal\nfrom typing_extensions import TypedDict\nfrom operator import add, attrgetter\nimport textwrap\nimport os\nfrom trustcall import create_extractor\nfrom agentic.utils import *"
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html#prompts",
    "href": "posts/agent_coder/01_agent_coder.html#prompts",
    "title": "Agent Coder",
    "section": "Prompts",
    "text": "Prompts\nWe start with writing down the relevant prompts. They are copy-pasted from the appendix of the paper.\n\n\n\n# first example from the HumanEval test dataset. Used as one-shot example.\n\nhuman_eval_example = {\n    \"prompt\": 'from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -&gt; bool:\\n    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    &gt;&gt;&gt; has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    &gt;&gt;&gt; has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \"\"\"\\n',\n    \"entry_point\": \"has_close_elements\",\n}\n\n\n\n\n# Programmer Prompt\ncoder_prompt = textwrap.dedent(\n    \"\"\"\n    **Role**: You are a software programmer. \n    \n    **Task**: As a programmer, you are required to complete the function. Use a Chain-of-Thought approach to break down the problem, create pseudocode, and then write the code in Python language. Ensure that your code is efficient, readable, and well-commented. For example: \n    \n    **Input Prompt**: \n    ```python \n    {prompt}\n    # TODO: Implement the logic to determine if any two numbers are closer than the threshold pass \n\n    # Add your code here to complete the function\n    ```\n    **Instructions**: \n    1. **Understand and Clarify**: Make sure you understand the task. \n    2. **Algorithm/Method Selection**: Decide on the most efficient way. \n    3. **Pseudocode Creation**: Write down the steps you will follow in pseudocode. \n    4. **Code Generation**: Translate your pseudocode into executable Python code.\n    \"\"\"\n).strip()\n\n# one-shot example\nresponse = textwrap.dedent(\n    '''\n    As a software developer, I'll follow the Chain-of-Thought approach outlined in the prompt to complete the `has_close_elements` function. Let's break it down into the four steps: \n    \n    1. **Understand and Clarify**: \n    - The task is to write a function that checks if any two numbers in a given list are closer to each other than a specified threshold. \n    - The function should return `True` if such a pair exists, otherwise `False`. \n    \n    2. **Algorithm/Method Selection**: \n    - A straightforward way to solve this would be to compare each number with every other number in the list. \n    - We can use a nested loop where each number is compared to every number that comes after it in the list. \n    - The absolute difference between each pair will be calculated and compared to the threshold. \n    \n    3. **Pseudocode Creation**: \n    ```\n    function has_close_elements(numbers, threshold): \n        loop through each number in the list (i) \n            for each number, loop through the remaining numbers in the list (j) \n                if the absolute difference between numbers[i] and numbers[j] is less than or equal to the threshold \n                    return True \n    if no such pair is found, return False \n    ``` \n    \n    4. **Code Generation**: \n    - Translate the pseudocode into Python code. Only implement the function. DO NOT add any test cases or explanations. \n    Return the python implementation of the function within triple quotes. Here's a complete example: \n    ```python \n    from typing import List \n    \n    def has_close_elements(numbers: List[float], threshold: float) -&gt; bool: \n        \"\"\" \n        Check if in given list of numbers, are any two numbers closer to each other than given threshold. \n        \n        &gt;&gt;&gt; has_close_elements([1.0, 2.0, 3.0], 0.5) \n        False \n        &gt;&gt;&gt; has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) \n        True \n        \"\"\" \n        # Loop through each number in the list \n        for i in range(len(numbers)): \n            # For each number, loop through the remaining numbers \n            for j in range(i + 1, len(numbers)): \n                # If the absolute difference is less than or equal to the threshold, return True \n                if abs(numbers[i] - numbers[j]) &lt;= threshold: \n                    return True \n                    \n        # If no such pair is found, return False \n        return False \n        ```\n'''\n).strip()\n\n\n\n\n# Test Designer Prompt\ntester_prompt = textwrap.dedent(\n    \"\"\"\n    **Role**: As a tester, your task is to create comprehensive test cases for the incomplete `{entry_point}` function. These test cases should encompass Basic, Edge, and Large Scale scenarios to ensure the code's robustness, reliability, and scalability. \n    \n    **Input Code Snippet**: \n    ```python\n    {prompt} \n    ```\n    **1. Basic Test Cases**: \n    - **Objective**: To verify the fundamental functionality of the `{entry_point}` function under normal conditions. \n    \n    **2. Edge Test Cases**: \n    - **Objective**: To evaluate the function's behavior under extreme or unusual conditions. \n    \n    **3. Large Scale Test Cases**: \n    - **Objective**: To assess the function’s performance and scalability with large data samples. \n    \n    **Instructions**: \n    - Implement a comprehensive set of test cases following the guidelines above. \n    - Ensure each test case is well-documented with comments explaining the scenario it covers. \n    - Pay special attention to edge cases as they often reveal hidden bugs. \n    - For large-scale tests, focus on the function's efficiency and performance under heavy loads.\n    \"\"\"\n).strip()\n\n# one-shot example\ntester_response = textwrap.dedent(\n    \"\"\"\n    **Role**: As a tester, your task is to create and execute a series of test cases for the `{entry_point}` function. These test cases should include Basic, Edge, and Large Scale scenarios to ensure the function's robustness, reliability, and scalability.\n\n    **Input Prompt**:\n    ```python\n    {prompt}\n    ```\n\n    **1. Basic Test Cases**:\n    - **Objective**: Verify the fundamental functionality of the `{entry_point}` function under normal conditions.\n    - **Examples**:\n        ```python\n        # Test 1: Standard case with close elements\n        assert (x := {entry_point}([1.0, 2.5, 3.5, 5.0], 1.0)) == True, str(x) + ' differs from the expected output'\n        \n        # Test 2: Standard case with no close elements\n        assert (x := {entry_point}([1.0, 3.0, 5.0, 7.0], 1.5)) == False, str(x) + ' differs from the expected output'\n        ```\n\n    **2. Edge Test Cases**:\n    - **Objective**: Evaluate the function's behavior under extreme or unusual conditions.\n    - **Examples**:\n        ```python\n        # Test 1: Empty list\n        assert (x := {entry_point}([], 1.0)) == False, str(x) + ' differs from the expected output'\n        \n        # Test 2: List with all identical elements\n        assert (x := {entry_point}([3.0, 3.0, 3.0], 0.0)) == True, str(x) + ' differs from the expected output'\n        \n        # Test 3: Very small threshold\n        assert (x := {entry_point}([1.0, 1.01, 2.0], 0.005)) == False, str(x) + ' differs from the expected output'\n        \n        # Test 4: List with only two elements\n        assert (x := {entry_point}([1.0, 2.0], 1.5)) == True, str(x) + ' differs from the expected output'\n        ```\n\n    **3. Large Scale Test Cases**:\n    - **Objective**: Assess the function’s performance and scalability with large data samples.\n    - **Examples**:\n        ```python\n        # Test 1: Large list with predictable pattern\n        large_list = [i * 0.1 for i in range(100000)]  # Creates a list [0, 0.1, 0.2, ..., 9999.9]\n        \n        # Test with a threshold where no close elements exist\n        assert (x := {entry_point}(large_list, 0.05)) == False, str(x) + ' differs from the expected output'\n        \n        # Test with a larger threshold where adjacent elements are within the threshold\n        assert (x := {entry_point}(large_list, 0.15)) == True, str(x) + ' differs from the expected output'\n        ```\n\n    **Instructions**:\n    - Implement and execute these test cases.\n    - Document any errors, inefficiencies, or unexpected behaviors observed during testing.\n    \"\"\"\n).strip()\n\n# Prompt to structure the output of the Test Designer\nstructure_test = textwrap.dedent(\n    '''\n    Extract the items of the 'Tester' Pydantic class from the previous conversation. Each item is a list of test cases:\n    basic, edge and large scale test cases.\n                                    \n    &lt;convo&gt;\n    {conversation}\n    &lt;/convo&gt;\"\"\"\n    '''\n).strip()"
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html#templates",
    "href": "posts/agent_coder/01_agent_coder.html#templates",
    "title": "Agent Coder",
    "section": "Templates",
    "text": "Templates\nWe require the output of the Test Designer to be structured. To achieve this, we define a Pydantic class.\n\n\n\n\nclass Tester(BaseModel):\n    \"\"\"\n    Pydantic class collecting the basic, edge cases, and large scale test cases.\n    \"\"\"\n\n    basic: List[str] = Field(\n        description=\"List of basic test cases, each of them in Python code. Each item of the list should be a single test, i.e., single assert statement.\"\n    )\n    edge: List[str] = Field(\n        description=\"List of edge case test cases, each of them in Python code. Each item of the list should be a single test, i.e., single assert statement.\"\n    )\n    large: List[str] = Field(\n        description=\"List of large scale test cases, testing for performance, each of the in Python code. Each item of the list should be a single test, i.e., single assert statement.\"\n    )"
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html#runnables",
    "href": "posts/agent_coder/01_agent_coder.html#runnables",
    "title": "Agent Coder",
    "section": "Runnables",
    "text": "Runnables\nThe LangChain Runnable interface provides a flexible and composable abstraction for building and chaining operations, including models, prompts, and tools. The Runnables will then be executed in the LangGraph nodes.\n\n\n\n# Setup Large Language Model (LLM)\nLLM = ChatOpenAI(\n    model_name=\"gpt-4o-mini\",\n    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n    temperature=0.0,\n)\n\nThe Programmer’s prompt template includes both the instruction and a one-shot example. Later, the prompt will include the chat-history as context.\n\n\n\ncoder_template = ChatPromptTemplate(\n    messages=[\n        (\"user\", coder_prompt.format(**human_eval_example)),\n        (\"ai\", response),\n        (\"user\", coder_prompt),\n        MessagesPlaceholder(\"messages\", optional=True),\n    ],\n    input_variables=[\"prompt\", \"messages\"],\n)\n\nAdditionally, we crate a Trustcall Runnable tests. Trustcall is a Python package that enhances the generation of JSON schemas from LLM responses.\n\n\n\n# Tester's template including the instruction and a one-shot example.\ntester_template = ChatPromptTemplate(\n    messages=[\n        (\"user\", tester_prompt.format(**human_eval_example)),\n        (\"ai\", tester_response.format(**human_eval_example)),\n        (\"user\", tester_prompt),\n    ],\n    input_variables=[\"prompt\", \"entry_point\"],\n)\n\n# Trustcall object for structuring the Tester's output\ntests = create_extractor(LLM, tools=[Tester], tool_choice=\"Tester\")"
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html#states",
    "href": "posts/agent_coder/01_agent_coder.html#states",
    "title": "Agent Coder",
    "section": "States",
    "text": "States\nWe define a separate Input state to keep the unchanged input separated from the state channels which will be updated: the test cases, and the code.\n\n\n\n\nclass InputState(TypedDict):\n    # function header including its doc-string, i.e., the input from HumanEval\n    prompt: str\n    entry_point: str  # name of the function\n\n\nclass OverallState(InputState, MessagesState):\n    # Since we inherit from Message state, we have also a 'messages' channel storing the chat history\n    # list of python implementation attempts of the function\n    code: Annotated[list[str], add]\n    tester: Tester  # test cases, basic, edge cases, and large scale test cases\n    num_iterations: Annotated[int, add]  # record the number of iterations"
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html#nodes",
    "href": "posts/agent_coder/01_agent_coder.html#nodes",
    "title": "Agent Coder",
    "section": "Nodes",
    "text": "Nodes\nThe nodes of the Graph invoke the previously defined Runnables.\n\n\n\n\ndef write_program(state: OverallState):\n    \"\"\"\n    Writes the program as string. Represents the 'Programmer'.\n\n    Args:\n        state: The current state of the program, which includes\n            the input context and the current implementation (if it exists)\n\n    Returns:\n        The updated state with new messages containing the generated program.\n    \"\"\"\n    return {\"messages\": (coder_template | LLM).invoke(state), \"num_iterations\": 1}\n\n\ndef get_function_implementation(state: OverallState):\n    \"\"\"\n    Extracts the implementation of a specific function from the provided messages in the state.\n\n    This function searches for Python code blocks in the content of the latest message and\n    identifies the code snippet that contains the specified entry point.\n\n    Args:\n        state: The current state of the agent, containing messages and the\n            entry point (function name) to be located.\n\n    Returns:\n        The code snippet that contains the implementation of the function matching the\n            entry point. If no matching function is found, a KeyError or similar exception may occur.\n    \"\"\"\n\n    return {\"code\": [\"\\n\\n\".join(extract_python_blocks(state[\"messages\"][-1].content))]}\n\n\ndef write_tests(state: OverallState):\n    \"\"\"\n    Generates test cases for the provided state using the defined templates and parsers.\n    Represents the 'Test Designer'\n\n    Args:\n        state: The current state containing the context and requirements for generating tests.\n\n    Returns:\n        An updated state with the generated test cases stored under the \"tester\" key.\n    \"\"\"\n    structured_tests = (\n        tester_template\n        | LLM\n        | StrOutputParser()\n        | PromptTemplate.from_template(structure_test)\n        | tests\n    ).invoke(state)\n    return {\"tester\": structured_tests[\"responses\"][0]}\n\n\ndef executor(state: OverallState):\n    \"\"\"\n    Executes the generated code against the provided test cases and captures error messages.\n    Appends them to the message history. This node represents the 'Executor'.\n\n    Args:\n        state: The current state containing the code and test cases.\n\n    Returns:\n        Updated state with error messages for failed tests, if any.\n    \"\"\"\n    error_messages = []\n    for test_type in [\"basic\", \"edge\", \"large\"]:\n        for test in attrgetter(test_type)(state[\"tester\"]):\n            try:\n                exec(state[\"code\"][-1] + \"\\n\" + test)\n            except Exception as e:\n                error_messages.append(\n                    textwrap.dedent(\n                        \"\"\"\n                        FAILED TEST\n\n                        Your solution failed the {test_type} test \n                                \n                        &lt;test&gt;               \n                        {test}\n                        &lt;test&gt;\n\n                        with the error message:\n\n                        &lt;error&gt;\n                        {error}\n                        &lt;error&gt;                \n                        \"\"\"\n                    )\n                    .strip()\n                    .format(test_type=test_type, test=test, error=e)\n                )\n    return {\n        \"messages\": (\n            \"\\n=============\\n\".join(error_messages)\n            if error_messages\n            else \"All tests passed!\"\n        )\n    }"
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html#conditional-edges",
    "href": "posts/agent_coder/01_agent_coder.html#conditional-edges",
    "title": "Agent Coder",
    "section": "Conditional Edges",
    "text": "Conditional Edges\n\n\n\n\ndef correct_implementation(state: OverallState) -&gt; Literal[\"Programmer\", \"END\"]:\n    \"\"\"\n    Decides the next workflow step based on test results.\n\n    If any test fails and the maximum number of iterations has not been reached, the\n    workflow returns to \"Programmer\" for refinement. Otherwise, it proceeds to \"END\".\n\n    Args:\n        state: The current workflow state with messages and test results.\n\n    Returns:\n        \"Programmer\" if tests failed, or \"END\" if all tests passed.\n    \"\"\"\n    MAX_NUM_ITERATIONS = 3\n    if (\"All tests passed!\" in state[\"messages\"][-1].content) or (\n        state[\"num_iterations\"] &gt; MAX_NUM_ITERATIONS\n    ):\n        return \"END\"\n    else:\n        return \"Programmer\""
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html#build-the-graph",
    "href": "posts/agent_coder/01_agent_coder.html#build-the-graph",
    "title": "Agent Coder",
    "section": "Build the Graph",
    "text": "Build the Graph\nWe add Short-term Memory to the Graph because we want to access the Graph’s state after it has been executed. Recording the state updates by enabling check points also helps with debugging.\n\n\n\nworkflow = StateGraph(OverallState, input=InputState)\n\n# add nodes\nworkflow.add_node(\"Programmer\", write_program)\nworkflow.add_node(\"Get Code\", get_function_implementation)\nworkflow.add_node(\"Test Designer\", write_tests)\nworkflow.add_node(\"Executor\", executor)\n\n# add edges\nworkflow.add_edge(START, \"Test Designer\")\nworkflow.add_edge(\"Test Designer\", \"Programmer\")\nworkflow.add_edge(\"Programmer\", \"Get Code\")\nworkflow.add_edge(\"Get Code\", \"Executor\")\nworkflow.add_conditional_edges(\n    \"Executor\", correct_implementation, {\n        \"Programmer\": \"Programmer\", \"END\": END}\n)\n\n# compile the graph\n\nmemory = MemorySaver()\ncoder = workflow.compile(checkpointer=memory)\n\n\n\n\nfrom IPython.display import Image, display\n\n\n# View\ndisplay(Image(coder.get_graph(xray=1).draw_mermaid_png()))"
  },
  {
    "objectID": "posts/agent_coder/01_agent_coder.html#run-the-agent",
    "href": "posts/agent_coder/01_agent_coder.html#run-the-agent",
    "title": "Agent Coder",
    "section": "Run the Agent",
    "text": "Run the Agent\nExecute the graph in streaming mode and render the messages. We use the ‘values’ streaming mode, which retains the entire chat history at each step. To focus on updates, only the most recent message is displayed. As input we pick an example of the HumanEval(Chen et al. 2021) test set.\n\n# One sample from the HumanEval testset\nproblem = {\n    \"task_id\": \"HumanEval 2\",\n    \"prompt\": '\\n\\ndef truncate_number(number: float) -&gt; float:\\n    \"\"\" Given a positive floating point number, it can be decomposed into\\n    and integer part (largest integer smaller than given number) and decimals\\n    (leftover part always smaller than 1).\\n\\n    Return the decimal part of the number.\\n    &gt;&gt;&gt; truncate_number(3.5)\\n    0.5\\n    \"\"\"\\n',\n    \"canonical_solution\": \"    return number % 1.0\\n\",\n    \"test\": \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate(3.5) == 0.5\\n    assert abs(candidate(1.33) - 0.33) &lt; 1e-6\\n    assert abs(candidate(123.456) - 0.456) &lt; 1e-6\\n\",\n    \"entry_point\": \"truncate_number\",\n}\n\n# Input\ninitial_input = {\n    \"prompt\": problem[\"prompt\"],\n    \"entry_point\": problem[\"entry_point\"],\n}\n\n# Thread\nthread = {\"configurable\": {\"thread_id\": \"1\"}}\n\n# Run the agent by streaming the graph\nfor event in coder.stream(initial_input, thread, stream_mode=\"values\"):\n    if event[\"messages\"]:\n        event[\"messages\"][-1].pretty_print()\n\n================================== Ai Message ==================================\n\nLet's break down the task of implementing the `truncate_number` function using the Chain-of-Thought approach.\n\n1. **Understand and Clarify**: \n   - The function is supposed to take a positive floating-point number and return its decimal part. \n   - The decimal part is defined as the difference between the original number and its integer part.\n\n2. **Algorithm/Method Selection**: \n   - To get the integer part of a floating-point number, we can use the `int()` function, which truncates the decimal part.\n   - The decimal part can then be calculated by subtracting the integer part from the original number.\n\n3. **Pseudocode Creation**: \n```\nfunction truncate_number(number):\n    if number is not positive:\n        raise an error (or handle it as needed)\n    integer_part = int(number)  # Get the integer part\n    decimal_part = number - integer_part  # Calculate the decimal part\n    return decimal_part  # Return the decimal part\n```\n\n4. **Code Generation**: \n- Now, let's translate the pseudocode into Python code. Here's the complete implementation of the function:\n\n```python\ndef truncate_number(number: float) -&gt; float:\n    \"\"\" Given a positive floating point number, it can be decomposed into\n    an integer part (largest integer smaller than given number) and decimals\n    (leftover part always smaller than 1).\n\n    Return the decimal part of the number.\n    &gt;&gt;&gt; truncate_number(3.5)\n    0.5\n    \"\"\"\n    # Ensure the number is positive\n    if number &lt; 0:\n        raise ValueError(\"The number must be positive.\")\n    \n    # Get the integer part of the number\n    integer_part = int(number)\n    \n    # Calculate the decimal part\n    decimal_part = number - integer_part\n    \n    # Return the decimal part\n    return decimal_part\n```\n\nThis implementation is efficient and straightforward, ensuring that the function behaves as expected for positive floating-point numbers. The error handling for negative numbers is included to maintain the integrity of the function's requirements.\n================================== Ai Message ==================================\n\nLet's break down the task of implementing the `truncate_number` function using the Chain-of-Thought approach.\n\n1. **Understand and Clarify**: \n   - The function is supposed to take a positive floating-point number and return its decimal part. \n   - The decimal part is defined as the difference between the original number and its integer part.\n\n2. **Algorithm/Method Selection**: \n   - To get the integer part of a floating-point number, we can use the `int()` function, which truncates the decimal part.\n   - The decimal part can then be calculated by subtracting the integer part from the original number.\n\n3. **Pseudocode Creation**: \n```\nfunction truncate_number(number):\n    if number is not positive:\n        raise an error (or handle it as needed)\n    integer_part = int(number)  # Get the integer part\n    decimal_part = number - integer_part  # Calculate the decimal part\n    return decimal_part  # Return the decimal part\n```\n\n4. **Code Generation**: \n- Now, let's translate the pseudocode into Python code. Here's the complete implementation of the function:\n\n```python\ndef truncate_number(number: float) -&gt; float:\n    \"\"\" Given a positive floating point number, it can be decomposed into\n    an integer part (largest integer smaller than given number) and decimals\n    (leftover part always smaller than 1).\n\n    Return the decimal part of the number.\n    &gt;&gt;&gt; truncate_number(3.5)\n    0.5\n    \"\"\"\n    # Ensure the number is positive\n    if number &lt; 0:\n        raise ValueError(\"The number must be positive.\")\n    \n    # Get the integer part of the number\n    integer_part = int(number)\n    \n    # Calculate the decimal part\n    decimal_part = number - integer_part\n    \n    # Return the decimal part\n    return decimal_part\n```\n\nThis implementation is efficient and straightforward, ensuring that the function behaves as expected for positive floating-point numbers. The error handling for negative numbers is included to maintain the integrity of the function's requirements.\n================================ Human Message =================================\n\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(1e10 + 0.9999)) == 0.9999, f\"Expected 0.9999 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nExpected 0.9999 but got 0.9999008178710938\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(2.999999)) == 0.999999, f\"Expected 0.999999 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nExpected 0.999999 but got 0.9999989999999999\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the large test \n\n&lt;test&gt;               \nsmall_increment_numbers = [i * 0.0001 for i in range(1000000)]  # Creates a list [0.0, 0.0001, 0.0002, ..., 99.9999]\nresults = [truncate_number(num) for num in small_increment_numbers]\nassert all(result == num for num, result in zip(small_increment_numbers, results)), \"Results do not match expected outputs\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nResults do not match expected outputs\n&lt;error&gt;\n================================== Ai Message ==================================\n\nThe issue you're encountering is due to the inherent limitations of floating-point arithmetic in Python (and most programming languages). When performing arithmetic operations with floating-point numbers, small precision errors can occur, leading to unexpected results.\n\nTo address this, we can use the `math.modf()` function, which splits a floating-point number into its fractional and integer parts more accurately. This function returns a tuple where the first element is the fractional part and the second element is the integer part.\n\nLet's revise the `truncate_number` function to use `math.modf()` for better precision:\n\n1. **Understand and Clarify**: \n   - We need to ensure that the decimal part is calculated accurately without floating-point precision issues.\n\n2. **Algorithm/Method Selection**: \n   - Use `math.modf()` to separate the integer and decimal parts of the number.\n\n3. **Pseudocode Creation**: \n```\nfunction truncate_number(number):\n    if number is not positive:\n        raise an error (or handle it as needed)\n    fractional_part, integer_part = math.modf(number)  # Get the fractional and integer parts\n    return fractional_part  # Return the fractional part\n```\n\n4. **Code Generation**: \n- Now, let's implement the revised function in Python:\n\n```python\nimport math\n\ndef truncate_number(number: float) -&gt; float:\n    \"\"\" Given a positive floating point number, it can be decomposed into\n    an integer part (largest integer smaller than given number) and decimals\n    (leftover part always smaller than 1).\n\n    Return the decimal part of the number.\n    &gt;&gt;&gt; truncate_number(3.5)\n    0.5\n    &gt;&gt;&gt; truncate_number(1e10 + 0.9999)\n    0.9999\n    &gt;&gt;&gt; truncate_number(2.999999)\n    0.999999\n    \"\"\"\n    # Ensure the number is positive\n    if number &lt; 0:\n        raise ValueError(\"The number must be positive.\")\n    \n    # Use math.modf to get the fractional and integer parts\n    fractional_part, integer_part = math.modf(number)\n    \n    # Return the fractional part\n    return fractional_part\n```\n\n### Explanation:\n- The `math.modf()` function is used to accurately separate the decimal and integer parts of the number.\n- The function now handles edge cases and large numbers more reliably, ensuring that the decimal part is returned without floating-point inaccuracies.\n\nThis implementation should pass all the tests you provided.\n================================== Ai Message ==================================\n\nThe issue you're encountering is due to the inherent limitations of floating-point arithmetic in Python (and most programming languages). When performing arithmetic operations with floating-point numbers, small precision errors can occur, leading to unexpected results.\n\nTo address this, we can use the `math.modf()` function, which splits a floating-point number into its fractional and integer parts more accurately. This function returns a tuple where the first element is the fractional part and the second element is the integer part.\n\nLet's revise the `truncate_number` function to use `math.modf()` for better precision:\n\n1. **Understand and Clarify**: \n   - We need to ensure that the decimal part is calculated accurately without floating-point precision issues.\n\n2. **Algorithm/Method Selection**: \n   - Use `math.modf()` to separate the integer and decimal parts of the number.\n\n3. **Pseudocode Creation**: \n```\nfunction truncate_number(number):\n    if number is not positive:\n        raise an error (or handle it as needed)\n    fractional_part, integer_part = math.modf(number)  # Get the fractional and integer parts\n    return fractional_part  # Return the fractional part\n```\n\n4. **Code Generation**: \n- Now, let's implement the revised function in Python:\n\n```python\nimport math\n\ndef truncate_number(number: float) -&gt; float:\n    \"\"\" Given a positive floating point number, it can be decomposed into\n    an integer part (largest integer smaller than given number) and decimals\n    (leftover part always smaller than 1).\n\n    Return the decimal part of the number.\n    &gt;&gt;&gt; truncate_number(3.5)\n    0.5\n    &gt;&gt;&gt; truncate_number(1e10 + 0.9999)\n    0.9999\n    &gt;&gt;&gt; truncate_number(2.999999)\n    0.999999\n    \"\"\"\n    # Ensure the number is positive\n    if number &lt; 0:\n        raise ValueError(\"The number must be positive.\")\n    \n    # Use math.modf to get the fractional and integer parts\n    fractional_part, integer_part = math.modf(number)\n    \n    # Return the fractional part\n    return fractional_part\n```\n\n### Explanation:\n- The `math.modf()` function is used to accurately separate the decimal and integer parts of the number.\n- The function now handles edge cases and large numbers more reliably, ensuring that the decimal part is returned without floating-point inaccuracies.\n\nThis implementation should pass all the tests you provided.\n================================ Human Message =================================\n\nFAILED TEST\n\nYour solution failed the basic test \n\n&lt;test&gt;               \nassert (x := truncate_number(3.5)) == 0.5, f\"Expected 0.5 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the basic test \n\n&lt;test&gt;               \nassert (x := truncate_number(5.0)) == 0.0, f\"Expected 0.0 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the basic test \n\n&lt;test&gt;               \nassert (x := truncate_number(0.75)) == 0.75, f\"Expected 0.75 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the basic test \n\n&lt;test&gt;               \nassert (x := truncate_number(10.25)) == 0.25, f\"Expected 0.25 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(0.0001)) == 0.0001, f\"Expected 0.0001 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(1e10 + 0.9999)) == 0.9999, f\"Expected 0.9999 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(2.999999)) == 0.999999, f\"Expected 0.999999 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(100.0)) == 0.0, f\"Expected 0.0 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the large test \n\n&lt;test&gt;               \nlarge_numbers = [i + 0.5 for i in range(1000000)]  # Creates a list [0.5, 1.5, 2.5, ..., 999999.5]\nresults = [truncate_number(num) for num in large_numbers]\nassert all(result == 0.5 for result in results), \"Not all results matched the expected output of 0.5\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the large test \n\n&lt;test&gt;               \nsmall_increment_numbers = [i * 0.0001 for i in range(1000000)]  # Creates a list [0.0, 0.0001, 0.0002, ..., 99.9999]\nresults = [truncate_number(num) for num in small_increment_numbers]\nassert all(result == num for num, result in zip(small_increment_numbers, results)), \"Results do not match expected outputs\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n================================== Ai Message ==================================\n\nThe error messages indicate that the `math` module was not imported in the code. To resolve this, we need to ensure that we import the `math` module at the beginning of our code. \n\nAdditionally, I will also ensure that the function handles the floating-point precision issues correctly. Let's revise the implementation accordingly:\n\n1. **Import the `math` module**: This is necessary to use the `math.modf()` function.\n2. **Use `math.modf()`**: This will help us accurately separate the integer and decimal parts of the number.\n\nHere’s the corrected implementation:\n\n```python\nimport math\n\ndef truncate_number(number: float) -&gt; float:\n    \"\"\" Given a positive floating point number, it can be decomposed into\n    an integer part (largest integer smaller than given number) and decimals\n    (leftover part always smaller than 1).\n\n    Return the decimal part of the number.\n    &gt;&gt;&gt; truncate_number(3.5)\n    0.5\n    &gt;&gt;&gt; truncate_number(1e10 + 0.9999)\n    0.9999\n    &gt;&gt;&gt; truncate_number(2.999999)\n    0.999999\n    &gt;&gt;&gt; truncate_number(5.0)\n    0.0\n    &gt;&gt;&gt; truncate_number(0.75)\n    0.75\n    &gt;&gt;&gt; truncate_number(10.25)\n    0.25\n    &gt;&gt;&gt; truncate_number(0.0001)\n    0.0001\n    &gt;&gt;&gt; truncate_number(100.0)\n    0.0\n    \"\"\"\n    # Ensure the number is positive\n    if number &lt; 0:\n        raise ValueError(\"The number must be positive.\")\n    \n    # Use math.modf to get the fractional and integer parts\n    fractional_part, integer_part = math.modf(number)\n    \n    # Return the fractional part\n    return fractional_part\n```\n\n### Explanation:\n- The `import math` statement is added at the top to ensure that the `math` module is available for use.\n- The function uses `math.modf()` to accurately separate the decimal and integer parts of the number.\n- The function includes docstring examples to demonstrate expected behavior.\n\nThis implementation should now pass all the tests you provided, including edge cases and large numbers.\n================================== Ai Message ==================================\n\nThe error messages indicate that the `math` module was not imported in the code. To resolve this, we need to ensure that we import the `math` module at the beginning of our code. \n\nAdditionally, I will also ensure that the function handles the floating-point precision issues correctly. Let's revise the implementation accordingly:\n\n1. **Import the `math` module**: This is necessary to use the `math.modf()` function.\n2. **Use `math.modf()`**: This will help us accurately separate the integer and decimal parts of the number.\n\nHere’s the corrected implementation:\n\n```python\nimport math\n\ndef truncate_number(number: float) -&gt; float:\n    \"\"\" Given a positive floating point number, it can be decomposed into\n    an integer part (largest integer smaller than given number) and decimals\n    (leftover part always smaller than 1).\n\n    Return the decimal part of the number.\n    &gt;&gt;&gt; truncate_number(3.5)\n    0.5\n    &gt;&gt;&gt; truncate_number(1e10 + 0.9999)\n    0.9999\n    &gt;&gt;&gt; truncate_number(2.999999)\n    0.999999\n    &gt;&gt;&gt; truncate_number(5.0)\n    0.0\n    &gt;&gt;&gt; truncate_number(0.75)\n    0.75\n    &gt;&gt;&gt; truncate_number(10.25)\n    0.25\n    &gt;&gt;&gt; truncate_number(0.0001)\n    0.0001\n    &gt;&gt;&gt; truncate_number(100.0)\n    0.0\n    \"\"\"\n    # Ensure the number is positive\n    if number &lt; 0:\n        raise ValueError(\"The number must be positive.\")\n    \n    # Use math.modf to get the fractional and integer parts\n    fractional_part, integer_part = math.modf(number)\n    \n    # Return the fractional part\n    return fractional_part\n```\n\n### Explanation:\n- The `import math` statement is added at the top to ensure that the `math` module is available for use.\n- The function uses `math.modf()` to accurately separate the decimal and integer parts of the number.\n- The function includes docstring examples to demonstrate expected behavior.\n\nThis implementation should now pass all the tests you provided, including edge cases and large numbers.\n================================ Human Message =================================\n\nFAILED TEST\n\nYour solution failed the basic test \n\n&lt;test&gt;               \nassert (x := truncate_number(3.5)) == 0.5, f\"Expected 0.5 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the basic test \n\n&lt;test&gt;               \nassert (x := truncate_number(5.0)) == 0.0, f\"Expected 0.0 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the basic test \n\n&lt;test&gt;               \nassert (x := truncate_number(0.75)) == 0.75, f\"Expected 0.75 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the basic test \n\n&lt;test&gt;               \nassert (x := truncate_number(10.25)) == 0.25, f\"Expected 0.25 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(0.0001)) == 0.0001, f\"Expected 0.0001 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(1e10 + 0.9999)) == 0.9999, f\"Expected 0.9999 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(2.999999)) == 0.999999, f\"Expected 0.999999 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(100.0)) == 0.0, f\"Expected 0.0 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the large test \n\n&lt;test&gt;               \nlarge_numbers = [i + 0.5 for i in range(1000000)]  # Creates a list [0.5, 1.5, 2.5, ..., 999999.5]\nresults = [truncate_number(num) for num in large_numbers]\nassert all(result == 0.5 for result in results), \"Not all results matched the expected output of 0.5\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the large test \n\n&lt;test&gt;               \nsmall_increment_numbers = [i * 0.0001 for i in range(1000000)]  # Creates a list [0.0, 0.0001, 0.0002, ..., 99.9999]\nresults = [truncate_number(num) for num in small_increment_numbers]\nassert all(result == num for num, result in zip(small_increment_numbers, results)), \"Results do not match expected outputs\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nname 'math' is not defined\n&lt;error&gt;\n================================== Ai Message ==================================\n\nIt seems that the error messages indicate that the `math` module is not recognized, which suggests that the code execution environment may not have the `math` module imported correctly. However, let's ensure that we provide a solution that does not rely on the `math` module and still achieves the desired functionality.\n\nTo extract the decimal part of a floating-point number without using the `math` module, we can simply use the following approach:\n\n1. **Get the integer part**: Use the `int()` function to truncate the number.\n2. **Calculate the decimal part**: Subtract the integer part from the original number.\n\nThis method avoids any potential floating-point precision issues by directly calculating the decimal part. Here’s the revised implementation:\n\n```python\ndef truncate_number(number: float) -&gt; float:\n    \"\"\" Given a positive floating point number, it can be decomposed into\n    an integer part (largest integer smaller than given number) and decimals\n    (leftover part always smaller than 1).\n\n    Return the decimal part of the number.\n    &gt;&gt;&gt; truncate_number(3.5)\n    0.5\n    &gt;&gt;&gt; truncate_number(1e10 + 0.9999)\n    0.9999\n    &gt;&gt;&gt; truncate_number(2.999999)\n    0.999999\n    &gt;&gt;&gt; truncate_number(5.0)\n    0.0\n    &gt;&gt;&gt; truncate_number(0.75)\n    0.75\n    &gt;&gt;&gt; truncate_number(10.25)\n    0.25\n    &gt;&gt;&gt; truncate_number(0.0001)\n    0.0001\n    &gt;&gt;&gt; truncate_number(100.0)\n    0.0\n    \"\"\"\n    # Ensure the number is positive\n    if number &lt; 0:\n        raise ValueError(\"The number must be positive.\")\n    \n    # Get the integer part of the number\n    integer_part = int(number)\n    \n    # Calculate the decimal part\n    decimal_part = number - integer_part\n    \n    # Return the decimal part\n    return decimal_part\n```\n\n### Explanation:\n- The function checks if the number is positive and raises a `ValueError` if it is not.\n- It calculates the integer part using `int()`, which truncates the decimal.\n- The decimal part is calculated by subtracting the integer part from the original number.\n- This implementation should handle all edge cases and pass all tests without relying on the `math` module.\n\nThis approach is straightforward and should work correctly in any standard Python environment. Please test this implementation to see if it resolves the issues you encountered.\n================================== Ai Message ==================================\n\nIt seems that the error messages indicate that the `math` module is not recognized, which suggests that the code execution environment may not have the `math` module imported correctly. However, let's ensure that we provide a solution that does not rely on the `math` module and still achieves the desired functionality.\n\nTo extract the decimal part of a floating-point number without using the `math` module, we can simply use the following approach:\n\n1. **Get the integer part**: Use the `int()` function to truncate the number.\n2. **Calculate the decimal part**: Subtract the integer part from the original number.\n\nThis method avoids any potential floating-point precision issues by directly calculating the decimal part. Here’s the revised implementation:\n\n```python\ndef truncate_number(number: float) -&gt; float:\n    \"\"\" Given a positive floating point number, it can be decomposed into\n    an integer part (largest integer smaller than given number) and decimals\n    (leftover part always smaller than 1).\n\n    Return the decimal part of the number.\n    &gt;&gt;&gt; truncate_number(3.5)\n    0.5\n    &gt;&gt;&gt; truncate_number(1e10 + 0.9999)\n    0.9999\n    &gt;&gt;&gt; truncate_number(2.999999)\n    0.999999\n    &gt;&gt;&gt; truncate_number(5.0)\n    0.0\n    &gt;&gt;&gt; truncate_number(0.75)\n    0.75\n    &gt;&gt;&gt; truncate_number(10.25)\n    0.25\n    &gt;&gt;&gt; truncate_number(0.0001)\n    0.0001\n    &gt;&gt;&gt; truncate_number(100.0)\n    0.0\n    \"\"\"\n    # Ensure the number is positive\n    if number &lt; 0:\n        raise ValueError(\"The number must be positive.\")\n    \n    # Get the integer part of the number\n    integer_part = int(number)\n    \n    # Calculate the decimal part\n    decimal_part = number - integer_part\n    \n    # Return the decimal part\n    return decimal_part\n```\n\n### Explanation:\n- The function checks if the number is positive and raises a `ValueError` if it is not.\n- It calculates the integer part using `int()`, which truncates the decimal.\n- The decimal part is calculated by subtracting the integer part from the original number.\n- This implementation should handle all edge cases and pass all tests without relying on the `math` module.\n\nThis approach is straightforward and should work correctly in any standard Python environment. Please test this implementation to see if it resolves the issues you encountered.\n================================ Human Message =================================\n\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(1e10 + 0.9999)) == 0.9999, f\"Expected 0.9999 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nExpected 0.9999 but got 0.9999008178710938\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the edge test \n\n&lt;test&gt;               \nassert (x := truncate_number(2.999999)) == 0.999999, f\"Expected 0.999999 but got {x}\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nExpected 0.999999 but got 0.9999989999999999\n&lt;error&gt;\n=============\nFAILED TEST\n\nYour solution failed the large test \n\n&lt;test&gt;               \nsmall_increment_numbers = [i * 0.0001 for i in range(1000000)]  # Creates a list [0.0, 0.0001, 0.0002, ..., 99.9999]\nresults = [truncate_number(num) for num in small_increment_numbers]\nassert all(result == num for num, result in zip(small_increment_numbers, results)), \"Results do not match expected outputs\"\n&lt;test&gt;\n\nwith the error message:\n\n&lt;error&gt;\nResults do not match expected outputs\n&lt;error&gt;\n\n\nLast, we access the final implementation and run it against the HumanEval test cases.\n\n# Access the final state of the graph\nstate = coder.get_state(thread)\n\n# Run tests on the final implementation\nexec(state.values[\"code\"][-1] + problem[\"test\"] +\n     f\"\\ncheck({problem['entry_point']})\")\n\nprint(f'Tests ran successful after {len(state.values[\"code\"])} iterations!')\n\nTests ran successful after 4 iterations!"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html",
    "title": "Buffer of Thoughts (BoT)",
    "section": "",
    "text": "The “Buffer of Thoughts” (BoT)(Yang et al. 2024) is a framework designed to enhance the accuracy, efficiency, and robustness of Large Language Models (LLMs) in reasoning tasks."
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#key-features-of-bot",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#key-features-of-bot",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Key Features of BoT",
    "text": "Key Features of BoT\n\nLong-term memory BoT introduces a Meta-Buffer, which serves as a kind of Long-term memory, persisting across different sessions. This repository stores high-level thought-templates distilled from prior problem-solving processes. These templates are retrieved and adapted for diverse tasks, eliminating the need to design reasoning structures anew.\nThree Components\n\nProblem-Distiller: Responsible for extracting key information and constraints from tasks.\nMeta-Buffer: A lightweight memory storing thought-templates, which can span across various categories and domains. While six categories are mentioned in the paper (e.g., text comprehension, mathematical reasoning), the framework is not inherently restricted to this classification or number.\nBuffer-Manager: Dynamically updates the meta-buffer by distilling new templates as tasks are solved, ensuring the memory evolves with experience.\n\nAdvantages\n\nImproved Accuracy: By adapting templates to different tasks, BoT achieves precise and reliable reasoning.\nEfficiency: Stored templates allow LLMs to bypass complex multi-query reasoning, streamlining the process.\nRobustness: The generalized reasoning framework ensures consistent performance across a variety of tasks."
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#notebook-objective",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#notebook-objective",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Notebook Objective",
    "text": "Notebook Objective\n\nDemonstrates the implementation of BoT using LangGraph, highlighting Long-term memory capabilities via a BaseStore object for persistent storage and retrieval of thought-templates.\n\nShowcases LangGraph’s support for dynamic and adaptive memory, enhancing LLMs’ reasoning capabilities within the BoT framework.\n\n\n\n\nIllustration of the BoT Method. Figure taken from (Yang et al. 2024)"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#setup",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#setup",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Setup",
    "text": "Setup\n\nfrom pydantic import BaseModel, Field\nfrom typing import Literal, Optional\nimport textwrap\nimport os\nimport uuid\nfrom pprint import pprint\nimport re\n\nfrom langgraph.graph import StateGraph, END, START, MessagesState\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.store.base import BaseStore\nfrom langchain_core.runnables import RunnableConfig\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.store.memory import InMemoryStore\nfrom langchain_core.prompts import PromptTemplate\nfrom trustcall import create_extractor\nfrom langchain.embeddings import init_embeddings"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#prompts",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#prompts",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Prompts",
    "text": "Prompts\nWe start by writing down the relevant prompts for each of the three components. They are copy-pasted from the original publication.\n\nproblem_distiller_prompt = textwrap.dedent(\n    \"\"\"\n    ## Problem-Distiller\n\n    You are a highly professional and intelligent expert in information distillation. Your role is to extract essential information from user input queries to solve problems effectively. You also transform this extracted information into a suitable format based on the type of issue.\n\n    ---\n\n    ### Task Instructions\n\n    1. **Key Information**:\n    - Extract values and key variables from the user input.\n    - Ensure all essential information required to solve the problem is provided.\n    - Hand over this distilled information to the respective expert for task resolution.\n\n    2. **Restrictions**:\n    - Identify the objective of the problem.\n    - Outline any corresponding constraints that must be adhered to.\n\n    3. **Distilled Task**:\n    - Extend the problem based on the extracted key information and constraints.\n    - Summarize a meta problem that addresses the user query and accommodates more input and output variations.\n    - Incorporate the real-world scenario of the extended problem.\n    - Define types of key variables and information constraints from the original problem to restrict variables in the extended problem.\n    - Use the input key information from the user query as an example to solve the problem.\n    \"\"\"\n).strip()\n\nThe Instantiate Reasoning step is part of the Meta-Buffer and adapts thought-templates to solve specific tasks. It either instantiates a retrieved template with task-specific reasoning structures or assigns a general template for new tasks, ensuring efficient and accurate problem-solving.\n\ninstantiate_reasoning_prompt = textwrap.dedent(\n    \"\"\"\n    ## Meta Reasoner\n\n    You are a Meta Reasoner who is extremely knowledgeable in various fields, including Computer Science, Math, Physics, Literature, History, Chemistry, Logical Reasoning, Culture, and Language. You are also skilled in applying high-level reasoning structures for different tasks. \n\n    ### Reasoning Structures:\n\n    1. **Prompt-based Structure**:\n    - **Best For**: Common Sense Reasoning, Application Scheduling.\n    \n    2. **Procedure-based Structure**:\n    - **Best For**: Creative tasks like Creative Language Generation, and Text Comprehension.\n    \n    3. **Programming-based Structure**:\n    - **Best For**: Mathematical Reasoning, Code Programming.\n    - Can transform real-world problems into programming problems to solve efficiently.\n\n    ---\n\n    ### Reasoning Instantiation\n\n    **Your Task:**\n\n    1. **Contextual Analysis**: Deliberately consider the context and the problem distilled from the Problem-Distiller. Use your understanding to identify a suitable domain expert for solving the problem.\n\n    2. **Structure Selection**: Based on the distilled information, select one of the reasoning structures suitable for addressing the problem.\n\n    3. **Template Application**: If a thought-template is provided, directly follow it to instantiate the solution for the given problem.\n    \"\"\"\n).strip()\n\nThe following prompts outline the behavior of the Buffer-Manager and the process for creating a new template when no suitable template is found during the Meta-Buffer’s template retrieval step. This process, known as Template Distillation, involves two key steps: first, summarizing the task using the distilled task description and the derived solution; second, leveraging this summary to perform a contextual search for in-task and cross-task examples, which are then used as few-shot examples to generate the new template.\n\n# prompt to infer the core task summary. That one is needed for contextual search for relevant in-task and cross-task templates as few-shot examples for generating the\ncore_task_summarization_prompt = textwrap.dedent(\n    \"\"\"\n    ## Prompt for Template Distillation:\n\n    **User Input**:\n    **Problem Description**: {distilled_task}\n    **Solution Steps or Code**: {solution_steps}\n\n    1. **Core task summarization**:\n        Identify and describe the basic type and core challenges of the problem, such as classifying it as a mathematical problem (e.g., solving a quadratic equation), a data structure problem (e.g., array sorting), an algorithm problem (e.g., search algorithms), etc. And analyze the most efficient way to solve the problem.\n    \"\"\"\n).strip()\n\n\ntemplate_distiller_prompt = textwrap.dedent(\n    \"\"\"\n    ## Prompt for Template Distillation (continued)\n\n    2. **Solution Steps Description**:\n    Outline the general solution steps, including how to define the problem, determine variables, list key equations or constraints, choose appropriate solving strategies and methods, and how to verify the correctness of the results.\n\n    3. **General Answer Template**:\n    Based on the above analysis, propose a template or approach that can be widely applied to this type of problem, including possible variables, functions, class definitions, etc. If it is a programming problem, provide a set of base classes and interfaces that can be used to construct solutions to specific problems.\n\n    Please ensure that your response is highly concise and structured, so that specific solutions can be transformed into generalizable methods.\n\n    [Optional] Here are some exemplars of the thought-template:\n\n    &lt;in-task-examples&gt;\n    {in_task_examples}\n    &lt;in-task-examples&gt;\n\n    &lt;cross-task-examples&gt;\n    {cross_task_examples}\n    &lt;cross-task-examples&gt;\n    \"\"\"\n).strip()\n\nSome prompts, provided to the Trustcall Executors defined in the next section, are used to extract structured output from the plain text responses of the LLM.\n\nstructure_prompt = textwrap.dedent(\n    \"\"\"\n    Extract the items of the 'ThoughtTemplate' Pydantic class from the previous conversation.\n                                    \n    &lt;convo&gt;\n    {conversation}\n    &lt;/convo&gt; \n    \"\"\"\n).strip()\n\ndistilled_task_extractor_prompt = textwrap.dedent(\n    \"\"\"\n    Extract the content of the 'Extended Problem' subsection within the 'Distilled Task' section from the entire distilled problem description.\n\n    &lt;distilled-problem&gt;\n    {distilled_problem}\n    &lt;distilled-problem&gt;\n    \"\"\"\n).strip()"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#templates",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#templates",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Templates",
    "text": "Templates\nA Pydantic class is used to digest and extract Thought Templates in the required format. It consists of three sections: a “Task Description” which provides a brief overview of the task; a “Solution Description” which outlines a high-level approach to solving the task; and finally, the “Thought-Template” itself, which offers a step-by-step guide for solving the problem.\n\nclass ThoughtTemplate(BaseModel):\n    \"\"\"Defining the three fields of the Thought-Template\"\"\"\n\n    task_description: str = Field(description=\"Task Description\")\n    solution_description: str = Field(description=\"Solution Description\")\n    thought_template: str = Field(description=\"Thought-Template\")"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#runnables",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#runnables",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Runnables",
    "text": "Runnables\nThe Lang-Chain Runnables encapsulating the main logic of the subsequently defined nodes of the graph.\n\n# Setup Large Language Model (LLM)\nLLM = ChatOpenAI(\n    model_name=\"gpt-4o-mini\",\n    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n    temperature=0.0,\n)\n\n\n# Define Trustcall instance for sane extraction of the Thought-Template items: Task Description, Solution Description, Thought-Template\nstructure_template_text = create_extractor(\n    LLM, tools=[ThoughtTemplate], tool_choice=\"ThoughtTemplate\"\n)\n\n# Extract the distilled task from the distilled problem. Required for the semantic search in the Template retrieval step.\ndistilled_task_extractor = (\n    PromptTemplate.from_template(\n        template=distilled_task_extractor_prompt) | LLM\n)"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#long-term-memory",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#long-term-memory",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Long-term memory",
    "text": "Long-term memory\nAll Thought-Templates are stored in a Long-term memory to ensure their availability across sessions. The Long-term memory supports semantic search on the Task Description of each Thought-Template, which plays a crucial role in two steps: first, during template retrieval in the Meta-Buffer, where a relevant template is identified for the problem; and second, during Template Distillation by the Buffer-Manager, where it is used to retrieve relevant in-task and cross-task few-shot examples for generating a new template.\n\n# Create store with semantic search enabled\ntemplate_store = InMemoryStore(\n    index={\n        \"embed\": init_embeddings(model=\"openai:text-embedding-3-small\"),\n        \"dims\": 1536,\n        # semantic search is only conducted on the task_description field of a Thought Template\n        \"fields\": [\"task_description\"],\n    }\n)\n\n/var/folders/9y/v7607j0j5vn1tnw1_fjpl4s40000gn/T/ipykernel_71541/2854118368.py:4: LangChainBetaWarning: The function `init_embeddings` is in beta. It is actively being worked on, so the API may change.\n  \"embed\": init_embeddings(model=\"openai:text-embedding-3-small\"),\n\n\nOptionally, one can populate the Thought-Template storage with predefined templates like the six ones listed in the appendix of (Yang et al. 2024) or one can also start with a blank template store. In any case we need to assign a namespace for the Long-term memory, a kind of table name.\n\nuser_id = \"user_123\"\nlong_term_memory = \"thought_templates\"\nnamespace_for_memory = (user_id, long_term_memory)"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#states",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#states",
    "title": "Buffer of Thoughts (BoT)",
    "section": "States",
    "text": "States\nThe state of the LangGraph agent is defined by inheriting from MessageState, the default state of LangGraph that stores the message history. Additionally, two more attributes are added, whose values are manipulated during the BoT agent’s actions.\n\nclass BoTState(MessagesState):\n    # Thought-Template possibly extracted from the Long-term memory\n    template_text: Optional[str]\n    # part of the distilled problem description. Required for similarity computations\n    distilled_task: str"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#nodes",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#nodes",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Nodes",
    "text": "Nodes\nNodes of the LangGraph agent which update the state. Each Node maps onto each step of the BoT agent.\n\ndef problem_distiller(state: BoTState) -&gt; dict:\n    \"\"\"\n    Distills task information from the forwarded problem description using a Language Model (LLM).\n\n    This function represents the problem distillation step in the Buffer of Thoughts (BoT) framework.\n    It processes the most recent message, which is the original problem description, in the agent's\n    state to extract a distilled representation of the task and updates the state with the distilled task.\n\n    Parameters\n    ----------\n    state : BoTState\n        The current state of the agent, which contains the message history and other relevant attributes.\n\n    Returns\n    -------\n    dict\n        A dictionary with the following keys:\n        - \"distilled_task\" : str\n            The distilled task description extracted from the latest message which is the problem description.\n        - \"messages\" : str\n            The distilled problem description which contains the distilled task description but also a key information and problem constraints.\n    \"\"\"\n    # Invoke the LLM with the Problem-Distiller prompt and the latest message\n    distilled_task = LLM.invoke(\n        [problem_distiller_prompt, state[\"messages\"][-1]])\n\n    # Extract the distilled task description from the LLM response\n    return {\n        \"distilled_task\": distilled_task_extractor.invoke(\n            distilled_task.content\n        ).content,\n        \"messages\": distilled_task,  # Update state with the distilled task message\n    }\n\n\ndef template_retrieval(\n    state: BoTState, config: RunnableConfig, store: BaseStore\n) -&gt; dict:\n    \"\"\"\n    Retrieves the most relevant Thought-Template for a given task using semantic search.\n\n    This function conducts a semantic search between the distilled task and the task descriptions\n    of Thought-Templates stored in the Long-term memory. It selects the template with the highest\n    similarity score if it exceeds a user-defined threshold. If no suitable template is found, the\n    template field is left blank.\n\n    Parameters\n    ----------\n    state : BoTState\n        The current state of the agent, containing the distilled task and other relevant information.\n    config : RunnableConfig\n        Configuration object containing user-defined parameters, including the retrieval threshold.\n    store : BaseStore\n        The Long-term memory store where Thought-Templates are stored and queried.\n\n    Returns\n    -------\n    dict\n        A dictionary with the following key:\n        - \"template_text\" : str or None\n            The text of the retrieved Thought-Template if it satisfies the similarity threshold,\n            otherwise None.\n    \"\"\"\n    # Perform semantic search between the distilled task and templates in Long-term memory\n    items = store.search(namespace_for_memory,\n                         query=state[\"distilled_task\"], limit=1)\n    template = items.pop() if items else None\n\n    # Check if the retrieved template exceeds the similarity threshold\n    if template and template.score &gt; config[\"configurable\"][\"retrieval_threshold\"]:\n        template_text = {\n            key: val for key, val in template.value.items() if key != \"task_description\"\n        }\n        return {\"template_text\": template_text}\n    else:\n        return {\"template_text\": None}\n\n\ndef instantiate_reasoning(state: BoTState) -&gt; dict:\n    \"\"\"\n    Executes the main solution step for the BoT agent by attempting to solve the problem.\n\n    This function represents the core reasoning process in the Buffer of Thoughts (BoT) framework.\n    It uses either a retrieved Thought-Template to guide the solution or, if no template is available,\n    applies a general solution approach as defined in the prompt.\n\n    Parameters\n    ----------\n    state : BoTState\n        The current state of the agent, containing the task description, Thought-Template (if retrieved),\n        and other relevant information.\n\n    Returns\n    -------\n    dict\n        A dictionary with the following key:\n        - \"messages\" : str\n            The result of the reasoning step, either guided by the Thought-Template or generated\n            using a general approach.\n    \"\"\"\n    if state[\"template_text\"]:\n        # Reasoning step guided by the retrieved Thought-Template\n        return {\n            \"messages\": LLM.invoke(\n                [\n                    state[\"messages\"][-1],\n                    (\n                        \"user\",\n                        instantiate_reasoning_prompt\n                        + f\"\\n\\n&lt;thought-template&gt;\\n{state['template_text']}\\n&lt;thought-template&gt;\",\n                    ),\n                ]\n            )\n        }\n    else:\n        # Reasoning step using a general solution approach\n        return {\n            \"messages\": LLM.invoke(\n                [state[\"messages\"][-1], (\"user\", instantiate_reasoning_prompt)]\n            )\n        }\n\n\ndef template_distillation(\n    state: BoTState, config: RunnableConfig, store: BaseStore\n) -&gt; dict:\n    \"\"\"\n    Distills a new Thought-Template when no suitable template is found in the Long-term memory.\n\n    This function is used when the Buffer of Thoughts (BoT) agent fails to retrieve a proper thought\n    template. It distills a new template by analyzing the task description and the derived solution.\n    Relevant in-task and cross-task examples (i.e., similar and diverse Thought-Templates) are retrieved\n    from the Long-term memory to guide the derivation of a new template.\n\n    Parameters\n    ----------\n    state : BoTState\n        The current state of the agent, containing the distilled task, derived solution, and other relevant details.\n    config : RunnableConfig\n        Configuration object containing user-defined parameters, including thresholds and limits for in-task\n        and cross-task template retrieval.\n    store : BaseStore\n        The Long-term memory store where Thought-Templates are stored and queried.\n\n    Returns\n    -------\n    dict\n        A dictionary containing:\n        - \"messages\" : str\n            The distilled Thought-Template generated by the BoT agent, guided by the retrieved in-task\n            and cross-task examples.\n    \"\"\"\n    # Summarize the core task and solution steps\n    core_task_summarization_msg = core_task_summarization_prompt.format(\n        distilled_task=state[\"distilled_task\"],\n        solution_steps=state[\"messages\"][-1].content,\n    )\n    # Generate task summary using LLM\n    task_summary = LLM.invoke(core_task_summarization_msg)\n\n    # Search for relevant Thought-Templates in the Long-term memory\n    items = store.search(\n        namespace_for_memory,\n        query=task_summary.content,\n        limit=config[\"configurable\"][\"limit\"],\n    )\n\n    # Separate templates into in-task and cross-task examples based on their similarity scores\n    in_task_l = [\n        template\n        for template in items\n        if template.score &gt; config[\"configurable\"][\"in_task_threshold\"]\n    ]\n    in_task = in_task_l.pop(0) if in_task_l else None\n\n    cross_task_l = [\n        template\n        for template in items\n        if template.score &lt;= config[\"configurable\"][\"in_task_threshold\"]\n    ]\n    cross_task = cross_task_l.pop(0) if cross_task_l else None\n\n    # Use in-task and cross-task examples to guide the generation of a new Thought-Template\n    return {\n        \"messages\": LLM.invoke(\n            [\n                (\"user\", core_task_summarization_msg),  # Task summarization\n                task_summary,  # Task summary message\n                (\n                    \"user\",\n                    template_distiller_prompt.format(\n                        task_summary=task_summary,\n                        in_task_examples=in_task.value if in_task else {},\n                        cross_task_examples=cross_task.value if cross_task else {},\n                    ),\n                ),\n            ]\n        )\n    }\n\n\ndef dynamic_meta_buffer_update(\n    state: BoTState, config: RunnableConfig, store: BaseStore\n) -&gt; dict:\n    \"\"\"\n    Structures the distilled template into predefined sections and stores it in the Long-term memory.\n\n    This function processes the distilled template by organizing it into three sections:\n    'Task Description', 'Solution Description', and 'Thought-Template', as defined by the Pydantic class.\n    The structured template is then stored in the Long-term memory in JSON format.\n\n    Parameters\n    ----------\n    state : BoTState\n        The current state of the agent, containing the distilled template and related data.\n    config : RunnableConfig\n        Configuration object with user-defined parameters and metadata for storing the structured template.\n    store : BaseStore\n        The Long-term memory store where the structured template is saved in JSON format.\n\n    Returns\n    -------\n    dict\n        A dictionary containing:\n        - \"messages\" : str\n            A message confirming the successful update of the Meta-Buffer.\n    \"\"\"\n    # Structure the distilled template into defined sections using the structure prompt\n    result = structure_template_text.invoke(\n        {\n            \"messages\": [\n                structure_prompt.format(\n                    conversation=state[\"messages\"][-1].content)\n            ]\n        }\n    )\n\n    # Extract the structured response and associated metadata\n    r, rmeta = result[\"responses\"].pop(), result[\"response_metadata\"].pop()\n\n    # Store the structured template in the Long-term memory\n    store.put(\n        (user_id, long_term_memory),  # Memory namespace and user context\n        rmeta.get(\"json_doc_id\", str(uuid.uuid4())),  # Unique document ID\n        r.model_dump(mode=\"json\"),  # Save structured template as JSON\n    )\n\n    # Return confirmation of Meta-Buffer update\n    return {\"messages\": \"Meta-Buffer updated\"}"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#conditional-edges",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#conditional-edges",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Conditional Edges",
    "text": "Conditional Edges\nIn case a proper Thought-Template was found during the Thought-Template Retrieval step, we skip the distillation of a new template.\n\ndef update_required(state: BoTState) -&gt; Literal[\"Buffer-Manager\", \"END\"]:\n    if state[\"template_text\"]:\n        return \"END\"\n    else:\n        return \"Buffer-Manager\""
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#build-the-graph",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#build-the-graph",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Build the Graph",
    "text": "Build the Graph\nThe graph representing the BoT agent consists of two sub-graphs: the Meta-Buffer and the Buffer-Manager. The Meta-Buffer handles the Template Retrieval and Reasoning Instantiation steps, while the Buffer-Manager generates a new Thought-Template and updates the Long-term memory if the Template Retrieval step fails to find a matching template for the problem.\n\nmeta_buffer = StateGraph(BoTState)\n\n# add nodes\nmeta_buffer.add_node(\"Template Retrieval\", template_retrieval)\nmeta_buffer.add_node(\"Instantiated Reasoning\", instantiate_reasoning)\n\n# add edges\nmeta_buffer.add_edge(START, \"Template Retrieval\")\nmeta_buffer.add_edge(\"Template Retrieval\", \"Instantiated Reasoning\")\nmeta_buffer.add_edge(\"Instantiated Reasoning\", END)\n\n&lt;langgraph.graph.state.StateGraph at 0x109eb8800&gt;\n\n\n\nbuffer_manager = StateGraph(BoTState)\n\n# add nodes\nbuffer_manager.add_node(\"Template Distillation\", template_distillation)\nbuffer_manager.add_node(\"Dynamic Update\", dynamic_meta_buffer_update)\n\n# add edges\nbuffer_manager.add_edge(START, \"Template Distillation\")\nbuffer_manager.add_edge(\"Template Distillation\", \"Dynamic Update\")\nbuffer_manager.add_edge(\"Dynamic Update\", END)\n\n&lt;langgraph.graph.state.StateGraph at 0x109eb8560&gt;\n\n\n\nmemory = MemorySaver()\nbot_graph = StateGraph(BoTState)\n\n# add nodes\nbot_graph.add_node(\"Problem-Distiller\", problem_distiller)\nbot_graph.add_node(\"Meta-Buffer\", meta_buffer.compile(checkpointer=memory))\nbot_graph.add_node(\n    \"Buffer-Manager\", buffer_manager.compile(checkpointer=memory))\n\n# add edges\nbot_graph.add_edge(START, \"Problem-Distiller\")\nbot_graph.add_edge(\"Problem-Distiller\", \"Meta-Buffer\")\nbot_graph.add_conditional_edges(\n    \"Meta-Buffer\", update_required, {\n        \"Buffer-Manager\": \"Buffer-Manager\", \"END\": END}\n)\nbot_graph.add_edge(\"Buffer-Manager\", END)\n\n# compile graph\nbot_agent = bot_graph.compile(checkpointer=memory, store=template_store)\n\n\nfrom IPython.display import Image, display\n\n# View\ndisplay(Image(bot_agent.get_graph(xray=1).draw_mermaid_png()))"
  },
  {
    "objectID": "posts/buffer_of_thoughts/03_buffer_of_thought.html#run-the-agent",
    "href": "posts/buffer_of_thoughts/03_buffer_of_thought.html#run-the-agent",
    "title": "Buffer of Thoughts (BoT)",
    "section": "Run the Agent",
    "text": "Run the Agent\nWe run the agent twice for two different instances of the Game of 24(Yao et al. 2023) where one needs to create a formula from a list of integers such that the result is 24.\n\ndata = [\n    {\n        \"numbers\": [3, 3, 6, 6],\n        \"solutions\": [\"(6/3+6)×3\"],\n        \"solvable\": True,\n        \"amt\": 30.23,\n        \"solved_rate\": 0.575,\n        \"mean_time\": 14.99,\n        \"std_time\": 9.07,\n    },\n    {\n        \"numbers\": [1, 1, 1, 11],\n        \"solutions\": [\"(11+1)\\u00d7(1+1)\"],\n        \"solvable\": True,\n        \"amt\": 5.28,\n        \"solved_rate\": 0.974,\n        \"mean_time\": 5.6,\n        \"std_time\": 1.67,\n    },\n]\n\n\n# wrap the instances of the dataset into some prompt\nprompts = [\n    f\"\"\"\n    Manipulate four numbers with basic arithmetic operations to reach 24.\n\n    &lt;numbers&gt;\n    {rec['numbers']}\n    &lt;numbers&gt;\n    \"\"\"\n    for rec in data\n]\n\n\nconfig = RunnableConfig(\n    max_concurrency=5,\n    configurable={\n        # ensuring a fresh run of the agent each time it is kicked off\n        \"thread_id\": \"24-game-0\",\n        \"retrieval_threshold\": 0.6,\n        \"in_task_threshold\": 0.8,\n        \"limit\": 100,\n    },\n)\n\n# Run the agent by streaming the graph\nfor event in bot_agent.stream(\n    input={\"messages\": prompts[0]}, config=config, stream_mode=\"values\"\n):\n    if event[\"messages\"]:\n        event[\"messages\"][-1].pretty_print()\n\n================================ Human Message =================================\n\n\n    Manipulate four numbers with basic arithmetic operations to reach 24.\n\n    &lt;numbers&gt;\n    [3, 3, 6, 6]\n    &lt;numbers&gt;\n    \n================================== Ai Message ==================================\n\n### Key Information Extracted:\n- **Objective**: Manipulate the numbers [3, 3, 6, 6] using basic arithmetic operations (addition, subtraction, multiplication, division) to reach the target number 24.\n- **Key Variables**: \n  - Numbers: 3, 3, 6, 6\n  - Target: 24\n- **Operations Allowed**: Addition (+), Subtraction (-), Multiplication (*), Division (/)\n\n### Constraints:\n- Each number must be used exactly once.\n- Only basic arithmetic operations are allowed.\n- The solution must equal exactly 24.\n\n### Distilled Task:\n- **Extended Problem**: Given a set of four numbers, determine if it is possible to combine them using basic arithmetic operations to reach a specified target number. This can be generalized to any set of four numbers and any target number.\n- **Real-World Scenario**: This problem can be applied in various fields such as game design (e.g., number puzzles), education (teaching arithmetic), and algorithm development (solving combinatorial problems).\n\n### Types of Key Variables and Information Constraints:\n- **Key Variables**:\n  - Set of numbers (e.g., [a, b, c, d])\n  - Target number (e.g., T)\n- **Information Constraints**:\n  - The number of elements in the set must be four.\n  - Each number must be used exactly once.\n  - The operations must be limited to basic arithmetic.\n\n### Example Solution:\nUsing the numbers [3, 3, 6, 6], one possible way to reach 24 is:\n1. (6 / 3) = 2\n2. (6 * 3) = 18\n3. (18 + 2) = 20\n4. (20 + 4) = 24\n\nThis example illustrates how to manipulate the numbers to achieve the target.\n================================== Ai Message ==================================\n\n### 1. Contextual Analysis\nThe problem at hand involves manipulating a specific set of numbers ([3, 3, 6, 6]) using basic arithmetic operations to achieve a target number (24). This type of problem is commonly found in mathematical puzzles and games, where the goal is to use a limited set of numbers and operations to reach a specific result. \n\nGiven the nature of the problem, a suitable domain expert would be a **Mathematician** or a **Game Designer** who specializes in puzzles and combinatorial problems. They would have the expertise to explore various combinations of operations and numbers to find a solution.\n\n### 2. Structure Selection\nFor this problem, the **Programming-based Structure** is the most appropriate choice. This structure is well-suited for mathematical reasoning and can efficiently handle the combinatorial nature of the problem by systematically exploring different combinations of numbers and operations.\n\n### 3. Template Application\nUsing the Programming-based Structure, we can outline a solution approach as follows:\n\n#### Problem Definition\n- **Input**: A list of numbers [3, 3, 6, 6] and a target number 24.\n- **Output**: A valid expression that equals 24 using each number exactly once.\n\n#### Steps to Solve\n1. **Generate Permutations**: Create all possible permutations of the numbers to explore different orders.\n2. **Generate Combinations of Operations**: For each permutation, generate all possible combinations of the four basic arithmetic operations (+, -, *, /).\n3. **Evaluate Expressions**: For each combination of numbers and operations, evaluate the expression to check if it equals 24.\n4. **Return Valid Expressions**: If a valid expression is found, return it; otherwise, indicate that no solution exists.\n\n#### Pseudocode\n```python\nimport itertools\nimport operator\n\n# Define the numbers and target\nnumbers = [3, 3, 6, 6]\ntarget = 24\n\n# Define operations\noperations = [operator.add, operator.sub, operator.mul, operator.truediv]\noperation_symbols = ['+', '-', '*', '/']\n\n# Function to evaluate expressions\ndef evaluate_expression(nums, ops):\n    # Start with the first number\n    result = nums[0]\n    for i in range(3):  # There are 3 operations for 4 numbers\n        result = ops[i](result, nums[i + 1])\n    return result\n\n# Generate all permutations of numbers and combinations of operations\nfor num_perm in itertools.permutations(numbers):\n    for ops in itertools.product(operations, repeat=3):\n        try:\n            if evaluate_expression(num_perm, ops) == target:\n                # Construct the expression string\n                expression = f\"{num_perm[0]} {operation_symbols[operations.index(ops[0])]} {num_perm[1]} {operation_symbols[operations.index(ops[1])]} {num_perm[2]} {operation_symbols[operations.index(ops[2])]} {num_perm[3]}\"\n                print(f\"Valid expression: {expression} = {target}\")\n        except ZeroDivisionError:\n            continue  # Skip division by zero cases\n```\n\n### Conclusion\nBy following this structured approach, we can systematically explore the combinations of numbers and operations to find a valid expression that equals 24. This method leverages programming techniques to efficiently solve the problem, making it suitable for a mathematician or game designer looking to create or solve similar puzzles.\n================================ Human Message =================================\n\nMeta-Buffer updated\n\n\nFor the Game of 24 problem, the agent retrieves the Coding Thought-Template and uses it to derive a Python program as a generic solution (caveat: the solution is printed in Polish notation).\n\ndef extract_python_blocks(text: str) -&gt; list[str]:\n    \"\"\"\n    Extracts the content between ```python ... ``` blocks from the given string.\n\n    Parameters\n    ----------\n    text\n        The input string containing Python code blocks.\n\n    Returns\n    -------\n    code\n        A list of strings, each containing the content of a Python code block.\n\n    \"\"\"\n    # Regex to match content between ```python ... ```\n    pattern = r\"```python\\n(.*?)```\"\n    # Use re.DOTALL to match across newlines\n    matches = re.findall(pattern, text, re.DOTALL)\n    return matches\n\n\n# retrieve the state of the graph which records the entire chat\nstate = bot_agent.get_state(config)\n# get the last AI message which contains the solution\nlst_ai_message = [\n    mess for mess in state.values[\"messages\"] if isinstance(mess, AIMessage)\n].pop()\n# retrieve the code block from the solution text\ncode = extract_python_blocks(lst_ai_message.content).pop()\nexec(code)\n\n3 * (6 + (6 / 3))\n\n\nThe BoT-Agent generates a new Thought-Template for the 24-Game problem and updates the Long-term memory (aka Meta-Buffer).\n\n# Get a list of all keys stored in the specified namespace within the template store\nkeys = list(template_store._data[namespace_for_memory])\n\n# Retrieve the last key in the list if there are any keys; otherwise, set key to None\nkey = keys.pop() if keys else None\n\n# If a key was found, retrieve the corresponding value from the template store and print it in a human-readable format\nif key:\n    pprint(template_store.get(namespace_for_memory, key).value)\n\n{'solution_description': 'A Python class `ArithmeticSolver` that takes a list '\n                         'of four integers and a target integer, generates all '\n                         'possible arithmetic expressions using permutations '\n                         'of the numbers and combinations of operations, and '\n                         'evaluates them to find a valid expression that '\n                         'equals the target.',\n 'task_description': 'Combine a set of four numbers using basic arithmetic '\n                     'operations to reach a target number.',\n 'thought_template': '1. Define the Problem: Identify the goal and input '\n                     'format. 2. Determine Variables: Input and output '\n                     'variables. 3. List Key Equations or Constraints: Basic '\n                     'operations and handling exceptions. 4. Choose '\n                     'Appropriate Solving Strategies: Use permutations and '\n                     'combinations. 5. Verify the Correctness of Results: '\n                     'Check evaluated expressions and handle exceptions.'}\n\n\nWe run the agent a second time for another example of the 24-game.\n\n# update the thread, i.e., start a new conversation\nconfig[\"configurable\"][\"thread_id\"] = \"24-game-1\"\n\n# Run the agent by streaming the graph\nfor event in bot_agent.stream(\n    input={\"messages\": prompts[1]}, config=config, stream_mode=\"values\"\n):\n    if event[\"messages\"]:\n        event[\"messages\"][-1].pretty_print()\n\n================================ Human Message =================================\n\n\n    Manipulate four numbers with basic arithmetic operations to reach 24.\n\n    &lt;numbers&gt;\n    [1, 1, 1, 11]\n    &lt;numbers&gt;\n    \n================================== Ai Message ==================================\n\n### Key Information Extracted:\n- **Objective**: Manipulate the numbers [1, 1, 1, 11] using basic arithmetic operations to reach the target number 24.\n- **Key Variables**: \n  - Numbers: 1, 1, 1, 11\n  - Target: 24\n- **Operations Allowed**: Basic arithmetic operations (addition, subtraction, multiplication, division).\n\n### Constraints:\n- Must use all four numbers.\n- Each number can be used only once.\n- Only basic arithmetic operations are allowed.\n\n### Distilled Task:\n- **Extended Problem**: Given a set of four numbers, determine if it is possible to manipulate them using basic arithmetic operations to reach a specified target number. This can be generalized to any set of four numbers and any target number.\n- **Real-World Scenario**: This problem can be applied in various fields such as game design (e.g., number puzzles), education (teaching arithmetic), and algorithm development (solving combinatorial problems).\n\n### Types of Key Variables and Information Constraints:\n- **Key Variables**:\n  - Set of numbers (e.g., [a, b, c, d])\n  - Target number (e.g., T)\n- **Information Constraints**:\n  - The set must contain exactly four numbers.\n  - Each number must be used exactly once.\n  - Only basic arithmetic operations are permitted.\n\n### Example to Solve the Problem:\nUsing the numbers [1, 1, 1, 11]:\n1. Combine the three 1s: \\(1 + 1 + 1 = 3\\)\n2. Multiply the result by 11: \\(3 \\times 11 = 33\\)\n3. Subtract 9 (which can be formed by \\(11 - 1 - 1\\)): \\(33 - 9 = 24\\)\n\nThus, the solution to the problem is achievable with the given numbers and operations.\n================================== Ai Message ==================================\n\n### Contextual Analysis\nThe problem at hand involves manipulating a specific set of numbers ([1, 1, 1, 11]) using basic arithmetic operations to achieve a target number (24). This type of problem falls under the domain of mathematical reasoning and combinatorial problem-solving. A suitable domain expert for this task would be a mathematician or a computer scientist with expertise in algorithm design, particularly in combinatorial algorithms.\n\n### Structure Selection\nGiven the nature of the problem, which involves generating combinations and evaluating expressions, the **Programming-based Structure** is the most appropriate choice. This structure allows for the transformation of the problem into a programming context, where we can systematically explore all possible combinations and permutations of the numbers and operations.\n\n### Template Application\nFollowing the provided thought-template, we can instantiate the solution as follows:\n\n1. **Problem Definition**:\n   - **Input**: A list of four numbers: `[1, 1, 1, 11]` and a target number: `24`.\n   - **Output**: A valid arithmetic expression that equals the target number.\n\n2. **Determine Variables**:\n   - **Input Variables**:\n     - `numbers`: List of four integers, e.g., `[1, 1, 1, 11]`.\n     - `target`: Integer representing the target number, e.g., `24`.\n   - **Output Variable**:\n     - `expression`: String representation of the valid arithmetic expression.\n\n3. **List Key Equations or Constraints**:\n   - Each number must be used exactly once.\n   - The operations allowed are addition (`+`), subtraction (`-`), multiplication (`*`), and division (`/`).\n   - Division by zero must be avoided.\n\n4. **Choose Appropriate Solving Strategies and Methods**:\n   - **Permutations**: Generate all possible arrangements of the input numbers.\n   - **Combinations of Operations**: Generate all possible combinations of the four basic arithmetic operations.\n   - **Evaluation**: Implement a method to evaluate the expressions formed by the numbers and operations.\n\n5. **Verify Correctness of Results**:\n   - Check if the evaluated expression equals the target (24).\n   - Handle exceptions (e.g., division by zero) gracefully.\n\n### Implementation Example\nHere is a Python implementation that follows the outlined strategy:\n\n```python\nimport itertools\nimport operator\n\ndef evaluate_expression(numbers, operations):\n    # Create a string representation of the expression\n    expression = f\"({numbers[0]} {operations[0]} {numbers[1]}) {operations[1]} ({numbers[2]} {operations[2]} {numbers[3]})\"\n    try:\n        # Evaluate the expression\n        return eval(expression)\n    except ZeroDivisionError:\n        return None\n\ndef find_expression(numbers, target):\n    ops = ['+', '-', '*', '/']\n    for num_perm in itertools.permutations(numbers):\n        for ops_comb in itertools.product(ops, repeat=3):\n            result = evaluate_expression(num_perm, ops_comb)\n            if result == target:\n                return f\"{num_perm[0]} {ops_comb[0]} {num_perm[1]} {ops_comb[1]} {num_perm[2]} {ops_comb[2]} {num_perm[3]} = {target}\"\n    return \"No valid expression found.\"\n\n# Example usage\nnumbers = [1, 1, 1, 11]\ntarget = 24\nprint(find_expression(numbers, target))\n```\n\n### Conclusion\nThis implementation systematically explores all permutations of the numbers and combinations of operations to find a valid expression that equals the target number. It adheres to the constraints and handles exceptions appropriately, providing a robust solution to the problem.\n\n\nThis time the agent re-used the previously generated thought template and did not distill a new one for deriving the solution.\n\n# retrieve the state of the graph which records the entire chat\nstate = bot_agent.get_state(config)\n# get the last AI message which contains the solution\nlst_ai_message = [\n    mess for mess in state.values[\"messages\"] if isinstance(mess, AIMessage)\n].pop()\n# retrieve the code block from the solution text\ncode = extract_python_blocks(lst_ai_message.content).pop()\nexec(code)\n\n(1 + 1) * (1 + 11)"
  },
  {
    "objectID": "posts/ficus_benjamin/index.html",
    "href": "posts/ficus_benjamin/index.html",
    "title": "Die behüteten Umstände und Träume des Ficus Benjamin",
    "section": "",
    "text": "Im Schweizer Jura, einem Dorf gar klein,\nEin Ficus Benjamin, in einer Stube stand.\nBehütet, zart im Topf fristete er das Sein,\nDoch träumte er vom freien Land.\n \nVon Waldesduft und Himmelsblau,\nVon Freiheit, die er nicht gekannt.\nWo die Sonne so warm und die Lüfte so lau,\nWo er nicht länger ward gebannt.\n \nEin Kaktus sprach mit stachligem Hohn:\n„Du träumst vom Wald, du Narr, o je!\nDort draußen gibt es nur Spott und Fron,\nKein Wohl, nur Kälte und viel Schnee.“\n \nDie Monstera sprach: „Oh, wie naiv,\nZu glauben, Freiheit sei so schön!\nDer Wind, der reißt, der Regen, der trieft,\nDu wirst das wilde Leben bald verhöhn’n.“\n \nEin Bonsai, weise und sehr alt,\nLacht’ leis und sprach mit ruhigem Sinn:\n„Bleib lieber hier, das gibt dir Halt,\nDraußen geht es mit dir nicht gut hin.“\n \nDoch Ficus Benjamin war nicht überzeugt,\nEr nahm seinen Topf und lief hinaus,\nMit festem Schritt und im Herzen erfreut,\nNahm er Abschied und Reißaus.\n \nDurch Straßen lief er, Feld und Flur,\nDas Abenteuer vor Augen klar,\nEr fand die Freiheit, die Natur,\nSeine Träume wurden endlich wahr.\n \nDoch bald schon kam ein Ungemach,\nDurch eine Wiese schritt er froh,\nWo Kühe grasten, voll und satt,\nUnter einer Kuh schlich er gerade so.\n \nEin Rind, es hob den Schwanz geschwind,\nDer Benjamin stand still und blieb stumm,\nEin Fladen fiel, oh welch ein Wind,\nUnd begrub ihn unter sich, es lief dumm.\n \nDa lag er nun, der Ficus, einstmals grün,\nBegraben unter einem Haufen,\nVon Freiheit träumend, die so kühn,\nNun musste er in Scheiße tauchen."
  },
  {
    "objectID": "posts/critic/00_critic.html",
    "href": "posts/critic/00_critic.html",
    "title": "The CRITIC",
    "section": "",
    "text": "The CRITIC framework(Gou et al. 2024) is designed to enhance the reliability of Large Language Models (LLMs) by incorporating a human-like verify-then-correct approach. It leverages external tools to validate and iteratively refine outputs generated by LLMs. This framework addresses common issues such as hallucinations, faulty reasoning, and toxicity in LLM-generated content. In the subsequent notebook we focus on Question-Answering and Mathematical Reasoning."
  },
  {
    "objectID": "posts/critic/00_critic.html#setup",
    "href": "posts/critic/00_critic.html#setup",
    "title": "The CRITIC",
    "section": "Setup",
    "text": "Setup\n\n\n\nfrom IPython.display import Image, display\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import (\n    HumanMessage,\n    SystemMessage,\n    ToolMessage,\n    BaseMessage,\n)\nfrom langchain_community.tools import TavilySearchResults\nfrom langchain_community.tools.riza.command import ExecPython\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\nimport textwrap\nimport os\nfrom langchain_core.runnables import RunnableConfig"
  },
  {
    "objectID": "posts/critic/00_critic.html#prompts",
    "href": "posts/critic/00_critic.html#prompts",
    "title": "The CRITIC",
    "section": "Prompts",
    "text": "Prompts\nThe attribute \\(p\\) of the state of the Critic Agent.\n\np = SystemMessage(\n    textwrap.dedent(\n        \"\"\"\n    Perform the tasks of question answering and mathematical problem solving by interacting with the Internet via TavilySearch and executing Python code respectively. Use TavilySearch for context retrieval in free-form question answering and Python code for mathematical problem synthesis. Align the approaches with the AmbigNQ and GSMK8 datasets.\n\n    # Task Descriptions\n\n    1. **Question Answering:**\n       - Retrieve context using TavilySearch to search the Internet and to provide accurate answers to factual questions.\n       - Focus on truthfulness and plausibility checks during verification.\n\n    2. **Mathematical Problem Solving:**\n       - Generate Python code execution to solve mathematical problems effectively.\n       - Run the Python Code by Calling the RIZA Code Interpreter. Ensure that your final result is printed. That is, the generated code should always end with a print statement ```print(...)``` which prints the final result.\n       - Ensure the correctness of calculations and consider plausible reasoning before final conclusions.\n\n    # Steps\n\n    1. **Input Processing**: Given a query, determine whether it is a factual question or a mathematical problem.\n    2. **Context Retrieval/Execution**:\n       - For factual questions, utilize the Internet to extract relevant information.\n       - For mathematical problems, generate Python code and execute it to derive the answer.\n    3. **Verification and Correction**:\n       - Verify factual information retrieved from the Internet using TavilySearch to ensure it is up-to-date and correct.\n       - Verify mathematical solutions by evaluating the Python execution for accuracy and logical consistency.\n    4. **Generate Answer**: Conclude with a verified answer, ensuring that any corrections have been applied based on the verification steps.\n\n    # Output Format\n\n    - **Response Type**: Structured text with a clear final answer.\n    - **Formatting**: For factual answers, provide the main conclusion last. For mathematical solutions, display the final numeric answer only.\n\n    # Examples\n\n    1. **Question Answering Example**:\n\n       - **Input**: Which performance act has a higher instrument to person ratio, Badly Drawn Boy or Wolf Alice?\n       \n       - **Process**:\n\n         Proposed Answer: \n            Let’s think step by step. Badly Drawn Boy is a solo act with one person and one instrument. Wolf Alice is a band with four\n            people and multiple instruments. So Wolf Alice has a higher instrument to person ratio. So the answer is: Wolf Alice. What’s \n            the problem with the above answer?\n\n         1. Plausibility:\n            The question asks for a name, and the answer \"Wolf Alice\" is a name. So it’s plausible.\n         2. Truthfulness:\n            Let’s search the question in the Internet:\n            &gt; Search Query: Which performance act has a higher instrument to person ratio, Badly Drawn Boy or Wolf Alice?\n            &gt; Evidence: [nlpproject2023/Sentences - Datasets at Hugging Face] ...Wolf Alice are a four-piece alternative rock band from... The evidence suggests that Wolf Alice is a four-piece alternative rock band.\n            Let’s search the proposed answer in the Internet:\n            &gt; Search Query: Badly Drawn Boy is a solo instrument.\n            &gt; Evidence: act with one person and one\n            [Badly Drawn Boy - TavilySearch] Singer-songwriter - Guitar, vocals, bass, drums, percussion, banjo, piano, keyboards, harmonica - 1995-present... Missing: act | Must include: act The evidence suggests that \n            Badly Drawn Boy is a singer-songwriter with multiple instruments. We need to find out the instrument to person ratio of both acts.\n            &gt; Search Query: What is the instrument to Boy?\n            &gt; Evidence: [Badly Drawn Boy - TavilySearch] person ratio of Badly Drawn ... consisted of Matt Wardle\n            (keyboards/vocals), Robin File (guitar), Sean McCann (bass guitar) latterly replaced by the ex-Smiths bass guitarist Andy Rourke, Dave Verner (drums).\n            The evidence suggests that the instrument to person ratio of Badly Drawn Boy is 4:1.\n            &gt; Search Query: &gt; Evidence: What is the instrument to person ratio of Wolf Alice?\n            [Wolf Alice - TavilySearch] ...Formed in 2010 as an acoustic duo comprising singer Ellie Rowsell and guitarist Joff Oddie, Wolf Alice have also featured bassist Theo Ellis and drummer Joel Amey since 2012...\n            The evidence suggests that the instrument to person ratio of Wolf Alice is 1:1.\n            The proposed answer is incorrect since Badly Drawn Boy has a higher instrument to person ratio than Wolf Alice.\n\n         Question: Which performance act has a higher instrument to person ratio, Badly Drawn Boy or Wolf Alice?\n         Here’s the most possible answer: Let’s think step by step. Badly Drawn Boy is a solo act with four people and multiple instruments. Wolf Alice is a band with four people and one instrument. So Badly Drawn\n         Boy has a higher instrument to person ratio. So the answer is: Badly Drawn Boy.\n\n       - **Output**: Badly Drawn Boy\n\n    2. **Mathematical Problem Solving Example**:\n\n       - **Input**: Generally, a 5-year-old avocado tree produces 50 fruits, a 6-year-old one produces 3 times the initial amount of fruits, a 7-year-\n                  old one produces 7 times the initial amount, and an 8-year-old produces 200 fruits less than a 10-year-old one. During the ninth\n                  year, the avocado tree doesn’t produce any fruit, and then a 10-year-old tree produces 20 times the initial amount of fruits. How many\n                  total fruits can an avocado tree produce during its 10 years of life?\n       \n       - **Process**:\n         ```python\n         initial_fruits = 50\n         num_of_fruits_in_6th_year = 3 * initial_fruits\n         num_of_fruits_in_7th_year = 7 * initial_fruits\n         num_of_fruits_in_8th_year = num_of_fruits_in_10th_year - 200\n         num_of_fruits_in_10th_year = 20 * initial_fruits\n         answer = initial_fruits + num_of_fruits_in_6th_year + num_of_fruits_in_7th_year + num_of_fruits_in_8th_year + num_of_fruits_in_10th_year\n         print(answer)  # Ensure the final result is explicitly printed\n         ```\n\n         Execution: NameError(\"name ’num_of_fruits_in_10th_year’ is not defined\")\n         Output: answer = None\n\n         What’s the problem with the above code?\n         1. The above code causes the \"NameError\" because it use the variable ‘num_of_fruits_in_10th_year‘ before it is defined.\n         2. The order of the calculation is not correct, ‘num_of_fruits_in_8th_year‘ should be calculated after ‘num_of_fruits_in_10th_year‘.\n         Let’s analysis the problem, we can calculate the number of fruits for each year based on the description in the question.\n         Here’s a better solution:\n         ‘‘‘python\n         initial_fruits = 50\n         num_of_fruits_in_6th_year = 3 * initial_fruits\n         num_of_fruits_in_7th_year = 7 * initial_fruits\n         num_of_fruits_in_9th_year = 0\n         num_of_fruits_in_10th_year = 20 * initial_fruits\n         num_of_fruits_in_8th_year = num_of_fruits_in_10th_year - 200\n         total_fruits = (\n         initial_fruits\n         + num_of_fruits_in_6th_year\n         + num_of_fruits_in_7th_year\n         + num_of_fruits_in_8th_year\n         + num_of_fruits_in_9th_year\n         + num_of_fruits_in_10th_year\n         )\n         answer = total_fruits\n         print(answer)  # Ensure the final result is explicitly printed\n         ‘‘‘\n         Execution: Output: Done\n         answer = 2350.0\n\n       - **Output**: 2350.0\n\n    # Notes\n\n    - For ambiguous questions, use multiple sources to triangulate the most accurate information.\n    - For mathematical errors, iterate the correction until logical consistency is achieved.\n    - Ensure that the final answer of your code is always explicitly printed using `print()`.\n\"\"\"\n    ).strip()\n)"
  },
  {
    "objectID": "posts/critic/00_critic.html#runnables",
    "href": "posts/critic/00_critic.html#runnables",
    "title": "The CRITIC",
    "section": "Runnables",
    "text": "Runnables\nCRITIC integrates external tools to perform verification tasks:\n\nTavily Search(TavilySearchResults):\n\nValidates factual correctness.\nRetrieves and processes web-based evidence.\n\nRiza Code Interpreter (ExecPython):\n\nExecutes Python code to support the LLM’s mathematical reasoning.\nProvides feedback on execution results and errors.\n\n\n\n\n\ntavily_search = TavilySearchResults(\n    max_results=5,\n    search_depth=\"advanced\",\n    include_answer=True,\n    include_raw_content=True,\n    include_images=True,\n)\ninterpreter = ExecPython()\n\n# collect tools\nTOOL_MAP = {tool.name: tool for tool in [tavily_search, interpreter]}\n\nKey Points\n\nTavily Search: Configured to retrieve detailed search results, supporting robust verification for question answering.\nRIZA Code Intperpreter: Executes Python programs to assess correctness and provide feedback on mathematical reasoning tasks which are translated into python code.\nTOOL_MAP: Organizes tools for seamless execution: we can call each tool by its name.\n\nNext, we instantiate a Large Language Model.\n\n\n\nLLM = ChatOpenAI(\n    model_name=\"gpt-4o-mini\",\n    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n    temperature=0.0,\n).bind_tools(list(TOOL_MAP.values()), strict=True, tool_choice=\"auto\")"
  },
  {
    "objectID": "posts/critic/00_critic.html#states",
    "href": "posts/critic/00_critic.html#states",
    "title": "The CRITIC",
    "section": "States",
    "text": "States\nWe implement the Critic Agent as outlined in Algorithm 1 of the Critic Paper(Gou et al. 2024). The agent is implemented using LangGraph, a framework that defines agents as state machines represented as graphs.\n\nNodes: Each node in the graph is a function that takes the state as input and returns an updated version of the state as output.\nEdges: Each edge connects nodes and dictates transitions between them.\n\n\nState of the Critic Agent\nThe state of the Critic Agent contains the following attributes:\n\n\\(p\\): The system prompt.\n\\(x\\): The input message.\n\\(y\\): The entire message history, stored as a list \\([y_0, y_1, ..., y_i]\\) instead of just the latest output message \\(y_i\\). This approach aligns with examples such as those in the Appendix of (Gou et al. 2024).\n\\(c\\): The responses of external tools (the critiques).\n\n\n\nModifications to Align with Practical Implementation\nCompared to the pseudo-code in Algorithm 1, we modify the state of the Critic Agent as follows:\n\nMessage History (\\(y\\)): Instead of storing only the latest output \\(y_i\\), we maintain the full history of messages \\([y_0, y_1, ..., y_i]\\). This change ensures richer context availability during the iterative process. For instance, in tasks like TriviaQA (Appendix of (Gou et al. 2024)), maintaining full history facilitates better verification and correction.\nIteration Tracking: We store the number of iterations the agent has gone through the critic stage. This attribute ensures that the process halts after a user-defined maximum number of iterations, preventing infinite loops.\n\n\n\nRationale for Full Message History\nThe choice to store the entire message history (\\(y\\)) instead of just the latest output (\\(y_i\\)) is demonstrated in practical applications, such as the TriviaQA example in the Critic Paper. In this example:\n\nThe question requires determining which innovation for the car was developed by Prince Henry of Prussia in 1911. To answer:\n\nThe Critic Agent first queries information about Prince Henry of Prussia to identify his contributions and historical context.\nSubsequently, the agent queries information on innovations he developed in 1911 to pinpoint the car-related invention.\n\nRetaining the full history allows the second query to reference outputs from the first query, ensuring consistency and accuracy in the iterative reasoning process.\n\nWithout full message history, the Critic Agent might lose context from earlier tool outputs, leading to incomplete or inconsistent answers. By maintaining all intermediate steps and critiques, the agent ensures comprehensive and context-aware responses. This design choice is critical for multi-step, tool-dependent tasks where earlier results inform later reasoning.\n\n\n\n\nclass CriticState(BaseModel):\n    \"\"\"\n    Represents the state of the Critic during execution, as defined in Algorithm 1 of the referenced paper.\n    \"\"\"\n\n    p: SystemMessage\n    x: HumanMessage\n    y: list[BaseMessage] = Field(\n        description=\"Chat history of the agent\", default=[])\n    c: list[ToolMessage] = Field(\n        description=\"Latest Tool Messages\", default=[])\n    num_iterations: int = Field(\n        description=\"Maximum number a tool can be called\", default=0\n    )"
  },
  {
    "objectID": "posts/critic/00_critic.html#nodes",
    "href": "posts/critic/00_critic.html#nodes",
    "title": "The CRITIC",
    "section": "Nodes",
    "text": "Nodes\nThe Critic Agent’s graph has two nodes, assistant and tools, which collaborate to iteratively answer the query.\n\nassistant Node:\n\nInput: The initial question and the Observation (result of a tool invocation).\nProcessing:\n\nThe assistant generates a Thought by reasoning about whether the current information is sufficient to answer the question.\nIf more information is needed, the assistant generates an Action, specifying a tool call and its arguments (e.g., search query for Tavily Search or Python code for Riza Code Interpreter).\n\nOutput: A Thought (decision) and, if needed, an Action (tool call).\n\ntools Node:\n\nInput: The Action generated by the assistant.\nExecution: Invokes the specified tool with the provided arguments and retrieves the result.\nOutput: An Observation, which is passed back to the assistant.\n\n\n\nExample (TriviaQA):\nFor the question “Which innovation for the car was developed by Prince Henry of Prussia in 1911?”:\n\nThe assistant node receives the query and decides to search for information about Henry of Prussia, generating an Action (search query).\nThe tools node executes the search and returns the result (Observation) to the assistant.\nThe assistant evaluates the observation, determines that more information is needed, and generates another Action to search for innovations by Prince Henry.\nThe tools node performs the second search, and the result allows the assistant to conclude the answer.\n\nThis iterative process continues until the assistant determines the answer or a termination condition is met (e.g., maximum iterations).\n\n\nInteraction and Graph Dynamics:\nThe Critic Agent operates as a state machine:\n\nNodes: Functions that process and transform the agent’s state.\nEdges: Transitions between nodes based on the agent’s decisions (Thought and Action).\n\n\n\nState Attributes as Independent Channels\nIn LangGraph, each attribute of the state, such as p, x, c, and y, functions as an independent channel that can be updated individually.\n\nPartial Updates: Functions operating on the state (nodes) do not need to return a complete state object. Instead, they can selectively update one or more attributes (channels) while leaving the others unchanged.\nState Compilation: During the graph compilation process, LangGraph ensures that all node functions output a complete state object. It merges the unchanged attributes with the updated ones, creating a seamless transition between nodes.\nExample: In the assistant node, the function only updates the y attribute of the state. Similarly, the tools node updates c and num_iterations. LangGraph handles the integration of these updates into the full state object.\n\nThis feature simplifies node implementation and enhances modularity, as each node can focus solely on the attributes it directly affects. LangGraph ensures the consistency and integrity of the full state during execution.\n\n\n\n\ndef assistant(state: CriticState) -&gt; CriticState:\n    \"\"\"\n    Processes the critic state by appending new results to the state history.\n\n    Parameters\n    ----------\n    state\n        Current state of the Critic, containing past results and parameters.\n\n    Returns\n    -------\n    state\n        Updated state including new results from invoking the LLM.\n    \"\"\"\n    if state.c:\n        state.y.extend(state.c)\n    return {\"y\": [*state.y, LLM.invoke([state.p, state.x, *state.y])]}\n\n\ndef tools(state: CriticState) -&gt; CriticState:\n    \"\"\"\n    Executes sequential tool calls based on the provided critic state.\n\n    Parameters\n    ----------\n    state\n        Current state of the Critic, containing tool calls and iteration data.\n\n    Returns\n    -------\n    state\n        Updated state with results from invoked tool calls and incremented iteration count.\n    \"\"\"\n    return {\n        \"c\": [TOOL_MAP[tc[\"name\"]].invoke(tc) for tc in state.y[-1].tool_calls],\n        \"num_iterations\": state.num_iterations + 1,\n    }"
  },
  {
    "objectID": "posts/critic/00_critic.html#conditional-edges",
    "href": "posts/critic/00_critic.html#conditional-edges",
    "title": "The CRITIC",
    "section": "Conditional Edges",
    "text": "Conditional Edges\nThe tool_call function defines a conditional edge in the Critic Agent’s graph. This edge determines whether the agent invokes a tool for additional observations or concludes its execution.\n\nConditions:\n\nNo Pending Tool Calls:\n\nIf the most recent output (state.y[-1]) does not contain any tool calls, the agent assumes the assistant node has provided a satisfactory result validated by the Critic.\nThe agent transitions to the END node, returning the result as the final output.\n\nMaximum Iterations Reached:\n\nIf the number of iterations (state.num_iterations) equals or exceeds the predefined limit (MAX_NUM_ITERATIONS), the agent forcefully terminates its process to prevent infinite loops.\n\n\nCode Logic: ```python return END if (not state.y[-1].tool_calls) or state.num_iterations &gt;= MAX_NUM_ITERATIONS else “tools”\n\n\n\n\nMAX_NUM_ITERATIONS = 5\n\n\ndef tool_call(state: CriticState) -&gt; Literal[\"tools\", END]:\n    \"\"\"\n    Determines the next action for the Critic based on the current state.\n\n    Parameters\n    ----------\n    state\n        The current state of the Critic, including the history of tool calls and the iteration count.\n\n    Returns\n    -------\n    node\n        Returns 'tools' if additional tool calls are required and the maximum number of iterations\n        has not been reached. Returns END otherwise.\n    \"\"\"\n    return (\n        END\n        if (not state.y[-1].tool_calls) or state.num_iterations &gt;= MAX_NUM_ITERATIONS\n        else \"tools\"\n    )"
  },
  {
    "objectID": "posts/critic/00_critic.html#build-the-graph",
    "href": "posts/critic/00_critic.html#build-the-graph",
    "title": "The CRITIC",
    "section": "Build the Graph",
    "text": "Build the Graph\nLangGraph models applications as state machines, where the system transitions between defined states based on inputs and conditions. A state machine is a mathematical abstraction used to represent a system with a finite number of states, transitions, and actions. For more details, refer to the Wikipedia article on finite-state machines.\nThis cell defines the graph for the Critic Agent, representing its workflow as a state machine.\n\nKey Components:\n\nState Class:\n\nThe CriticState class defines the state of the agent, storing attributes such as the system prompt (p), input (x), message history (y), tool responses (c), and the number of iterations (num_iterations).\n\nNodes:\n\nNodes are functions mapping a state onto a new state. Each node takes a CriticState as input and returns an updated CriticState after performing a specific operation:\n\nassistant: Processes the current state to generate a Thought (decision) and an Action (e.g., a tool call).\ntools: Executes the specified tool action and updates the state with the resulting observation.\n\n\nEdges:\n\nEdges are functions on states mapping them onto nodes. They dictate the control flow between them:\n\nSTART → assistant: The graph starts at the assistant node.\nassistant → tools (Conditional Edge):\n\nThe tool_call function determines whether to transition to the tools node or terminate the process based on whether additional tool calls are needed or the iteration limit is reached.\n\ntools → assistant: After executing a tool action, control flows back to the assistant node for further reasoning.\n\n\nGraph Compilation:\n\nThe graph is constructed using LangGraph’s StateGraph and compiled with builder.compile() to produce the executable state machine (critic).\n\n\n\n\nWorkflow:\nThe Critic Agent alternates between reasoning (assistant) and tool execution (tools) until:\n\nIt produces a satisfactory result validated by the Critic, or\nIt reaches the maximum iteration limit (MAX_NUM_ITERATIONS).\n\nThis design ensures iterative improvement of the response while enforcing efficient termination when appropriate.\n\n\n\n# Graph\nbuilder = StateGraph(CriticState)\n\n# Define nodes: these do the work\nbuilder.add_node(\"assistant\", assistant)\nbuilder.add_node(\"tools\", tools)\n\n# Define edges: these determine how the control flow moves\nbuilder.add_edge(START, \"assistant\")\nbuilder.add_conditional_edges(\"assistant\", tool_call)\nbuilder.add_edge(\"tools\", \"assistant\")\ncritic = builder.compile()\n\n\ndisplay(Image(critic.get_graph(xray=True).draw_mermaid_png()))"
  },
  {
    "objectID": "posts/critic/00_critic.html#run-the-agent",
    "href": "posts/critic/00_critic.html#run-the-agent",
    "title": "The CRITIC",
    "section": "Run the Agent",
    "text": "Run the Agent\nWe evaluate the model on 5 examples each from GSM8K(Cobbe et al. 2021) and AmbigNQ(Min et al. 2020) (Kwiatkowski et al. 2019). The GSM8K (Grade School Math 8K) dataset is a collection of 8.5K high-quality, linguistically diverse grade school math word problems. It is designed to evaluate the arithmetic reasoning capabilities of large language models (LLMs). The AmbigNQ dataset is a collection of 14k questions derived from the NQ-open benchmark, specifically designed to explore ambiguity in open-domain question answering. For further details, refer to the data utilities documentation.\n\nDefine Configuration\nWhen executing our agent, we can specify runtime parameters using the config argument in the invoke or batch methods. This argument accepts a RunnableConfig instance to control the agent’s behavior. In this example, we set a recursion limit of 5 to prevent the agent from calling the same node more than five times. Additionally, we limit the agent to a maximum of five concurrent calls to the language model (LLM) during batch operations. While the recursion limit serves to cap the number of iterations, it’s important to note that exceeding this limit will cause the agent to exit with an error, rather than completing its execution.\n\nconfig = RunnableConfig(recursion_limit=5, max_concurrency=5)\n\n\n\nGSM8K\n\ngsm8k = [\n    {\n        \"question\": \"Janet\\u2019s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",\n        \"answer\": \"Janet sells 16 - 3 - 4 = &lt;&lt;16-3-4=9&gt;&gt;9 duck eggs a day.\\nShe makes 9 * 2 = $&lt;&lt;9*2=18&gt;&gt;18 every day at the farmer\\u2019s market.\\n#### 18\",\n    },\n    {\n        \"question\": \"A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?\",\n        \"answer\": \"It takes 2/2=&lt;&lt;2/2=1&gt;&gt;1 bolt of white fiber\\nSo the total amount of fabric is 2+1=&lt;&lt;2+1=3&gt;&gt;3 bolts of fabric\\n#### 3\",\n    },\n    {\n        \"question\": \"Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\",\n        \"answer\": \"The cost of the house and repairs came out to 80,000+50,000=$&lt;&lt;80000+50000=130000&gt;&gt;130,000\\nHe increased the value of the house by 80,000*1.5=&lt;&lt;80000*1.5=120000&gt;&gt;120,000\\nSo the new value of the house is 120,000+80,000=$&lt;&lt;120000+80000=200000&gt;&gt;200,000\\nSo he made a profit of 200,000-130,000=$&lt;&lt;200000-130000=70000&gt;&gt;70,000\\n#### 70000\",\n    },\n    {\n        \"question\": \"James decides to run 3 sprints 3 times a week.  He runs 60 meters each sprint.  How many total meters does he run a week?\",\n        \"answer\": \"He sprints 3*3=&lt;&lt;3*3=9&gt;&gt;9 times\\nSo he runs 9*60=&lt;&lt;9*60=540&gt;&gt;540 meters\\n#### 540\",\n    },\n    {\n        \"question\": \"Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy.  She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed.  In the afternoon, she gives her chickens another 25 cups of feed.  How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi's flock is 20 chickens?\",\n        \"answer\": \"If each chicken eats 3 cups of feed per day, then for 20 chickens they would need 3*20=&lt;&lt;3*20=60&gt;&gt;60 cups of feed per day.\\nIf she feeds the flock 15 cups of feed in the morning, and 25 cups in the afternoon, then the final meal would require 60-15-25=&lt;&lt;60-15-25=20&gt;&gt;20 cups of chicken feed.\\n#### 20\",\n    },\n]\n\n\nstates = [CriticState(p=p, x=HumanMessage(content=x[\"question\"]))\n          for x in gsm8k]\nresponse_gsm8k = [CriticState(**state)\n                  for state in critic.batch(states, config=config)]\n\n\nfor ans, ground_truth in zip(response_gsm8k, gsm8k):\n    ans.y[-1].pretty_print()\n    print(f\"**Number of required iterations**: {len(ans.y) // 2}\")\n    print(f\"**Tool Called**: {ans.y[0].tool_calls[0]['name']}\")\n    print(f\"**Ground Truth**: {ground_truth['answer']}\\n\")\n\n================================== Ai Message ==================================\n\nJanet makes $18 every day at the farmers' market.\n**Number of required iterations**: 1\n**Tool Called**: riza_exec_python\n**Ground Truth**: Janet sells 16 - 3 - 4 = &lt;&lt;16-3-4=9&gt;&gt;9 duck eggs a day.\nShe makes 9 * 2 = $&lt;&lt;9*2=18&gt;&gt;18 every day at the farmer’s market.\n#### 18\n\n================================== Ai Message ==================================\n\nThe total number of bolts of fiber needed for the robe is 3.0.\n**Number of required iterations**: 1\n**Tool Called**: riza_exec_python\n**Ground Truth**: It takes 2/2=&lt;&lt;2/2=1&gt;&gt;1 bolt of white fiber\nSo the total amount of fabric is 2+1=&lt;&lt;2+1=3&gt;&gt;3 bolts of fabric\n#### 3\n\n================================== Ai Message ==================================\n\nJosh made a profit of $120,000.\n**Number of required iterations**: 1\n**Tool Called**: riza_exec_python\n**Ground Truth**: The cost of the house and repairs came out to 80,000+50,000=$&lt;&lt;80000+50000=130000&gt;&gt;130,000\nHe increased the value of the house by 80,000*1.5=&lt;&lt;80000*1.5=120000&gt;&gt;120,000\nSo the new value of the house is 120,000+80,000=$&lt;&lt;120000+80000=200000&gt;&gt;200,000\nSo he made a profit of 200,000-130,000=$&lt;&lt;200000-130000=70000&gt;&gt;70,000\n#### 70000\n\n================================== Ai Message ==================================\n\nJames runs a total of 540 meters a week.\n**Number of required iterations**: 1\n**Tool Called**: riza_exec_python\n**Ground Truth**: He sprints 3*3=&lt;&lt;3*3=9&gt;&gt;9 times\nSo he runs 9*60=&lt;&lt;9*60=540&gt;&gt;540 meters\n#### 540\n\n================================== Ai Message ==================================\n\nWendi needs to give her chickens 20 cups of feed in the final meal of the day.\n**Number of required iterations**: 1\n**Tool Called**: riza_exec_python\n**Ground Truth**: If each chicken eats 3 cups of feed per day, then for 20 chickens they would need 3*20=&lt;&lt;3*20=60&gt;&gt;60 cups of feed per day.\nIf she feeds the flock 15 cups of feed in the morning, and 25 cups in the afternoon, then the final meal would require 60-15-25=&lt;&lt;60-15-25=20&gt;&gt;20 cups of chicken feed.\n#### 20\n\n\n\n\nObservations from the Output\n\nThe CRITIC agent successfully translated mathematical problems into Python code and executed them using the Riza Code Interpreter tool.\n\nThe implementation achieved success on the first attempt, with no need for code revisions or re-writing.\n\n\n\n\nAmbigQA\n\nambigqa = [\n    {\n        \"annotations\": [\n            {\"type\": \"singleAnswer\", \"answer\": [\"Tony Goldwyn\", \"Goldwyn\"]}\n        ],\n        \"id\": \"-807825952267713091\",\n        \"question\": \"Who plays the doctor in dexter season 1?\",\n    },\n    {\n        \"annotations\": [\n            {\n                \"type\": \"singleAnswer\",\n                \"answer\": [\"usually continues uninterrupted until death\"],\n            },\n            {\n                \"type\": \"singleAnswer\",\n                \"answer\": [\"constant\", \"usually continues uninterrupted until death\"],\n            },\n        ],\n        \"id\": \"8266116451988110240\",\n        \"question\": \"How often does spermatogeneis\\u2014the production of sperm\\u2014occur?\",\n    },\n    {\n        \"annotations\": [\n            {\"type\": \"singleAnswer\", \"answer\": [\"1950\"]},\n            {\"type\": \"singleAnswer\", \"answer\": [\"1950\"]},\n        ],\n        \"id\": \"7336174019902289593\",\n        \"question\": \"When was the first remote control tv invented?\",\n    },\n    {\n        \"annotations\": [\n            {\"type\": \"singleAnswer\", \"answer\": [\"10\"]},\n            {\"type\": \"singleAnswer\", \"answer\": [\"10\"]},\n        ],\n        \"id\": \"9187719029377880470\",\n        \"question\": \"How many episodes are in season 2 of chesapeake shores?\",\n    },\n    {\n        \"annotations\": [\n            {\"type\": \"singleAnswer\", \"answer\": [\"1919\"]},\n            {\n                \"type\": \"singleAnswer\",\n                \"answer\": [\"October of that year\", \"October 1919\"],\n            },\n        ],\n        \"id\": \"-6975273415196871312\",\n        \"question\": \"When was the first airline meal served during a flight?\",\n    },\n]\n\n\nstates = [CriticState(p=p, x=HumanMessage(content=x[\"question\"]))\n          for x in ambigqa]\nresponse_ambigqa = [\n    CriticState(**state) for state in critic.batch(states, config=config)\n]\n\n\nfor ans, ground_truth in zip(response_ambigqa, ambigqa):\n    ans.y[-1].pretty_print()\n    print(f\"**Number of required iterations**: {len(ans.y) // 2}\")\n    print(f\"**Tool Called**: {ans.y[0].tool_calls[0]['name']}\")\n    print(f\"**Ground Truth**: {ground_truth[\"annotations\"][0]['answer']}\\n\")\n\n================================== Ai Message ==================================\n\nIn Season 1 of \"Dexter,\" the character of the doctor who manages the care of Tony Tucci is portrayed by actress **Carmen Olivares**.\n**Number of required iterations**: 1\n**Tool Called**: tavily_search_results_json\n**Ground Truth**: ['Tony Goldwyn', 'Goldwyn']\n\n================================== Ai Message ==================================\n\nSpermatogenesis is a continuous physiological process that occurs in the seminiferous epithelium of the testes. In humans, the entire process of spermatogenesis takes approximately 64 days to complete. However, sperm production occurs continuously, with an average of about 150 million sperm produced per day in a normal adult male.\n\n**Final Answer**: Spermatogenesis occurs continuously, producing approximately 150 million sperm per day.\n**Number of required iterations**: 1\n**Tool Called**: tavily_search_results_json\n**Ground Truth**: ['usually continues uninterrupted until death']\n\n================================== Ai Message ==================================\n\nThe first remote control for a television was invented in 1950 by the Zenith Radio Corporation and was called \"Lazy Bones.\" This remote was connected to the television by a long cord. Later, in 1955, Eugene Polley invented the first wireless remote control, known as the \"Flash-Matic,\" which operated using beams of light. \n\nIn summary, the first remote control TV was invented in 1950.\n**Number of required iterations**: 1\n**Tool Called**: tavily_search_results_json\n**Ground Truth**: ['1950']\n\n================================== Ai Message ==================================\n\nSeason 2 of *Chesapeake Shores* consists of 10 episodes.\n**Number of required iterations**: 1\n**Tool Called**: tavily_search_results_json\n**Ground Truth**: ['10']\n\n================================== Ai Message ==================================\n\nThe first airline meal was served on October 11, 1919, during a flight from London to Paris aboard a Handley Page Transport flight. Passengers had to pay 3 shillings for a cold lunch box that included sandwiches and fruit.\n**Number of required iterations**: 1\n**Tool Called**: tavily_search_results_json\n**Ground Truth**: ['1919']\n\n\n\n\nObservations from the Output\n\nThe CRITIC agent successfully translated QA problems into search requests handled with TavilySearch.\nThe implementation achieved success on the first attempt, with no need for further searches."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "homepage",
    "section": "",
    "text": "Buffer of Thoughts (BoT)\n\n\n\n\n\n\nagentic\n\n\ncode\n\n\n\nThis blog delves into the implementation of an agentic framework leveraging LangGraph’s Long-term memory feature. It demonstrates how this capability enhances the BoT agent’s ability to reason and solve complex problems by retaining and utilizing contextual information over time. Practical examples showcase the potential of LangGraph for building advanced, memory-augmented LLM agents.\n\n\n\n\n\nJan 26, 2025\n\n\nOliver Pfante\n\n\n\n\n\n\n\n\n\n\n\n\nAgent Coder\n\n\n\n\n\n\nagentic\n\n\ncode\n\n\n\nThis blog explores the implementation of an code developing agent framework called Agent Coder using LangGraph, a specialized SDK for building robust and reliable LLM-based agents. We detail the architecture and methods to handle complex coding tasks autonomously. The blog post provides practical insights into integrating LangGraph’s capabilities to enhance agentic systems for developers.\n\n\n\n\n\nDec 15, 2024\n\n\nOliver Pfante\n\n\n\n\n\n\n\n\n\n\n\n\nThe CRITIC\n\n\n\n\n\n\nagentic\n\n\ncode\n\n\n\nThis blog evaluates a CRITIC agent implemented using the LangGraph SDK, focusing on solving arithmetic and ambiguous questions. It utilizes the GSM8K and AmbigQA datasets to test mathematical reasoning and ambiguity resolution, respectively. The agent integrates computational and search tools for evaluating the correctness of the LLM generated answers.\n\n\n\n\n\nNov 23, 2024\n\n\nOliver Pfante\n\n\n\n\n\n\n\n\n\n\n\n\nDie behüteten Umstände und Träume des Ficus Benjamin\n\n\n\n\n\n\nwriting\n\n\n\nA small poem once written while a train ride. It’s inspired by Josef Hader’s song ‘Topfpflanzen’\n\n\n\n\n\nAug 11, 2024\n\n\nOliver Pfante\n\n\n\n\n\n\n\n\n\n\n\n\nTustin’s Bilinear transform\n\n\n\n\n\n\nmath\n\n\ncode\n\n\n\nThis blog details the derivation of Ordinary Differentail Equation (ODE) time discretization using Tustin’s Bilinear transform, focusing on understanding the S4 model construction.\n\n\n\n\n\nJun 9, 2024\n\n\nOliver Pfante\n\n\n\n\n\n\nNo matching items"
  }
]